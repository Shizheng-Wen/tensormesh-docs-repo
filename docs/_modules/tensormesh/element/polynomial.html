<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../../">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>tensormesh.element.polynomial &mdash; tensormesh  documentation</title>
      <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="../../../_static/css/mytheme.css?v=e73ece32" />
      <link rel="stylesheet" type="text/css" href="../../../_static/custom.css" />

  
    <link rel="shortcut icon" href="https://raw.githubusercontent.com/walkerchi/tensormesh_sphinx_theme/master/tensormesh_sphinx_theme/static/img/tensormesh_logo.webp"/>
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../../../_static/jquery.js?v=5d32c60e"></script>
        <script src="../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="../../../_static/documentation_options.js?v=5929fcd5"></script>
        <script src="../../../_static/doctools.js?v=9bcbadda"></script>
        <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../index.html">
            
              <img src="https://raw.githubusercontent.com/walkerchi/tensormesh_sphinx_theme/master/tensormesh_sphinx_theme/static/img/tensormesh_logo.webp" class="logo" alt="Logo"/>
          </a>
              <div class="version">
                0.1.0
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Get Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../get_started/installation.html">Installation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../get_started/installation.html#installatoion-via-pypi">Installatoion via PyPi</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../get_started/benchmark.html">Benchmark</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../get_started/benchmark.html#m2-pro-cpu">M2 Pro CPU</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../get_started/benchmark.html#assemble-speed">Assemble Speed</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../get_started/benchmark.html#pipeline-speed">Pipeline Speed</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../get_started/element.html">Basis</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../get_started/element.html#line">Line</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../get_started/element.html#triangle">Triangle</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../get_started/element.html#quadrilateral">Quadrilateral</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../get_started/element.html#tetrahedron">Tetrahedron</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../get_started/element.html#hexahedron">Hexahedron</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../get_started/element.html#pyramid">Pyramid</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../get_started/element.html#prism">Prism</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Examples</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../examples/mesh_gen.html">Mesh Generation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../examples/mesh_gen.html#d-high-order-mesh">2D high order mesh</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../examples/mesh_gen.html#d-high-circle-mesh">2D high circle mesh</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../examples/mesh_gen.html#d-hybrid-mesh">2D hybrid mesh</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../examples/mesh_gen.html#id1">3D high order mesh</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../examples/adjacency.html">Adjacency</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../examples/adjacency.html#d-node-adjacency">2D Node Adjacency</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../examples/adjacency.html#d-element-adjacency">2D Element Adjacency</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../examples/adjacency.html#id1">3D Node Adjacency</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../examples/adjacency.html#id2">3D Element Adjacency</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../examples/basis.html">Basis</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../examples/basis.html#d-line-basis">1D Line Basis</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../examples/basis.html#d-triangle-basis">2D Triangle Basis</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../examples/basis.html#d-quadrilateral-basis">2D Quadrilateral Basis</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../examples/basis.html#d-tetrahedron-basis">3D Tetrahedron Basis</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../examples/basis.html#d-hexahedron-basis">3D Hexahedron Basis</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../examples/basis.html#d-pyramid-basis">3D Pyramid Basis</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../examples/basis.html#d-prism-basis">3D Prism Basis</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../examples/values.html">Plot values</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../examples/values.html#d-point-value">2D Point Value</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../examples/values.html#d-element-value">2D Element Value</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../examples/values.html#id1">3D Point Value</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../examples/values.html#id2">3D Element Value</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../examples/poisson.html">Poisson Equation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../examples/poisson.html#adaptive-mesh-refinement">Adaptive Mesh Refinement</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../examples/wave.html">Wave Equation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../examples/wave.html#multi-frequency-dataset">multi frequency dataset</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../examples/linear_elasticity.html">Linear Elasticity</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../examples/linear_elasticity.html#pressed-hollow-rectangle">Pressed Hollow Rectangle</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../api_reference/dataset.html">tensormesh.dataset</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../api_reference/dataset.html#mesh">Mesh</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/dataset.html#tensormesh.dataset.mesh.MeshGen"><code class="docutils literal notranslate"><span class="pre">MeshGen</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/dataset.html#tensormesh.dataset.mesh.MeshGen.__init__"><code class="docutils literal notranslate"><span class="pre">MeshGen.__init__()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/dataset.html#tensormesh.dataset.mesh.MeshGen.add_rectangle"><code class="docutils literal notranslate"><span class="pre">MeshGen.add_rectangle()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/dataset.html#tensormesh.dataset.mesh.MeshGen.remove_rectangle"><code class="docutils literal notranslate"><span class="pre">MeshGen.remove_rectangle()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/dataset.html#tensormesh.dataset.mesh.MeshGen.add_circle"><code class="docutils literal notranslate"><span class="pre">MeshGen.add_circle()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/dataset.html#tensormesh.dataset.mesh.MeshGen.remove_circle"><code class="docutils literal notranslate"><span class="pre">MeshGen.remove_circle()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/dataset.html#tensormesh.dataset.mesh.MeshGen.add_cube"><code class="docutils literal notranslate"><span class="pre">MeshGen.add_cube()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/dataset.html#tensormesh.dataset.mesh.MeshGen.remove_cube"><code class="docutils literal notranslate"><span class="pre">MeshGen.remove_cube()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/dataset.html#tensormesh.dataset.mesh.MeshGen.add_sphere"><code class="docutils literal notranslate"><span class="pre">MeshGen.add_sphere()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/dataset.html#tensormesh.dataset.mesh.MeshGen.remove_sphere"><code class="docutils literal notranslate"><span class="pre">MeshGen.remove_sphere()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/dataset.html#tensormesh.dataset.mesh.MeshGen.gen"><code class="docutils literal notranslate"><span class="pre">MeshGen.gen()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../api_reference/dataset.html#equation">Equation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/dataset.html#tensormesh.dataset.equation.PoissonMultiFrequency"><code class="docutils literal notranslate"><span class="pre">PoissonMultiFrequency</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/dataset.html#tensormesh.dataset.equation.PoissonMultiFrequency.__init__"><code class="docutils literal notranslate"><span class="pre">PoissonMultiFrequency.__init__()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/dataset.html#tensormesh.dataset.equation.PoissonMultiFrequency.source_term"><code class="docutils literal notranslate"><span class="pre">PoissonMultiFrequency.source_term()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/dataset.html#tensormesh.dataset.equation.PoissonMultiFrequency.solution"><code class="docutils literal notranslate"><span class="pre">PoissonMultiFrequency.solution()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/dataset.html#tensormesh.dataset.equation.HeatMultiFrequency"><code class="docutils literal notranslate"><span class="pre">HeatMultiFrequency</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/dataset.html#tensormesh.dataset.equation.HeatMultiFrequency.__init__"><code class="docutils literal notranslate"><span class="pre">HeatMultiFrequency.__init__()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/dataset.html#tensormesh.dataset.equation.HeatMultiFrequency.initial_condition"><code class="docutils literal notranslate"><span class="pre">HeatMultiFrequency.initial_condition()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/dataset.html#tensormesh.dataset.equation.HeatMultiFrequency.solution"><code class="docutils literal notranslate"><span class="pre">HeatMultiFrequency.solution()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/dataset.html#tensormesh.dataset.equation.WaveMultiFrequency"><code class="docutils literal notranslate"><span class="pre">WaveMultiFrequency</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/dataset.html#tensormesh.dataset.equation.WaveMultiFrequency.__init__"><code class="docutils literal notranslate"><span class="pre">WaveMultiFrequency.__init__()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/dataset.html#tensormesh.dataset.equation.WaveMultiFrequency.initial_condition"><code class="docutils literal notranslate"><span class="pre">WaveMultiFrequency.initial_condition()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/dataset.html#tensormesh.dataset.equation.WaveMultiFrequency.solution"><code class="docutils literal notranslate"><span class="pre">WaveMultiFrequency.solution()</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_reference/mesh.html">tensormesh.mesh</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../api_reference/mesh.html#mesh">Mesh</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/mesh.html#tensormesh.mesh.Mesh"><code class="docutils literal notranslate"><span class="pre">Mesh</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/mesh.html#tensormesh.mesh.Mesh.points"><code class="docutils literal notranslate"><span class="pre">Mesh.points</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/mesh.html#tensormesh.mesh.Mesh.cells"><code class="docutils literal notranslate"><span class="pre">Mesh.cells</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/mesh.html#tensormesh.mesh.Mesh.point_data"><code class="docutils literal notranslate"><span class="pre">Mesh.point_data</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/mesh.html#tensormesh.mesh.Mesh.cell_data"><code class="docutils literal notranslate"><span class="pre">Mesh.cell_data</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/mesh.html#tensormesh.mesh.Mesh.field_data"><code class="docutils literal notranslate"><span class="pre">Mesh.field_data</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/mesh.html#tensormesh.mesh.Mesh.cell_sets"><code class="docutils literal notranslate"><span class="pre">Mesh.cell_sets</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/mesh.html#tensormesh.mesh.Mesh.dim2eletyp"><code class="docutils literal notranslate"><span class="pre">Mesh.dim2eletyp</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/mesh.html#tensormesh.mesh.Mesh.default_eletyp"><code class="docutils literal notranslate"><span class="pre">Mesh.default_eletyp</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/mesh.html#tensormesh.mesh.Mesh.default_element_type"><code class="docutils literal notranslate"><span class="pre">Mesh.default_element_type</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/mesh.html#id0"><code class="docutils literal notranslate"><span class="pre">Mesh.points</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/mesh.html#tensormesh.mesh.Mesh.__init__"><code class="docutils literal notranslate"><span class="pre">Mesh.__init__()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/mesh.html#id1"><code class="docutils literal notranslate"><span class="pre">Mesh.cells</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/mesh.html#id2"><code class="docutils literal notranslate"><span class="pre">Mesh.point_data</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/mesh.html#id3"><code class="docutils literal notranslate"><span class="pre">Mesh.cell_data</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/mesh.html#id4"><code class="docutils literal notranslate"><span class="pre">Mesh.field_data</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/mesh.html#id5"><code class="docutils literal notranslate"><span class="pre">Mesh.cell_sets</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/mesh.html#id6"><code class="docutils literal notranslate"><span class="pre">Mesh.dim2eletyp</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/mesh.html#id7"><code class="docutils literal notranslate"><span class="pre">Mesh.default_eletyp</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/mesh.html#tensormesh.mesh.Mesh.register_point_data"><code class="docutils literal notranslate"><span class="pre">Mesh.register_point_data()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/mesh.html#tensormesh.mesh.Mesh.register_element_data"><code class="docutils literal notranslate"><span class="pre">Mesh.register_element_data()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/mesh.html#tensormesh.mesh.Mesh.to_meshio"><code class="docutils literal notranslate"><span class="pre">Mesh.to_meshio()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/mesh.html#tensormesh.mesh.Mesh.dim"><code class="docutils literal notranslate"><span class="pre">Mesh.dim</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/mesh.html#tensormesh.mesh.Mesh.save"><code class="docutils literal notranslate"><span class="pre">Mesh.save()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/mesh.html#tensormesh.mesh.Mesh.to_file"><code class="docutils literal notranslate"><span class="pre">Mesh.to_file()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/mesh.html#tensormesh.mesh.Mesh.node_adjacency"><code class="docutils literal notranslate"><span class="pre">Mesh.node_adjacency()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/mesh.html#tensormesh.mesh.Mesh.element_adjacency"><code class="docutils literal notranslate"><span class="pre">Mesh.element_adjacency()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/mesh.html#tensormesh.mesh.Mesh.elements"><code class="docutils literal notranslate"><span class="pre">Mesh.elements()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/mesh.html#tensormesh.mesh.Mesh.clone"><code class="docutils literal notranslate"><span class="pre">Mesh.clone()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/mesh.html#tensormesh.mesh.Mesh.plot"><code class="docutils literal notranslate"><span class="pre">Mesh.plot()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/mesh.html#tensormesh.mesh.Mesh.n_points"><code class="docutils literal notranslate"><span class="pre">Mesh.n_points</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/mesh.html#tensormesh.mesh.Mesh.n_elements"><code class="docutils literal notranslate"><span class="pre">Mesh.n_elements</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/mesh.html#tensormesh.mesh.Mesh.boundary_mask"><code class="docutils literal notranslate"><span class="pre">Mesh.boundary_mask</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/mesh.html#id8"><code class="docutils literal notranslate"><span class="pre">Mesh.default_element_type</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/mesh.html#tensormesh.mesh.Mesh.dtype"><code class="docutils literal notranslate"><span class="pre">Mesh.dtype</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/mesh.html#tensormesh.mesh.Mesh.device"><code class="docutils literal notranslate"><span class="pre">Mesh.device</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/mesh.html#tensormesh.mesh.Mesh.from_meshio"><code class="docutils literal notranslate"><span class="pre">Mesh.from_meshio()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/mesh.html#tensormesh.mesh.Mesh.read"><code class="docutils literal notranslate"><span class="pre">Mesh.read()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/mesh.html#tensormesh.mesh.Mesh.from_file"><code class="docutils literal notranslate"><span class="pre">Mesh.from_file()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/mesh.html#tensormesh.mesh.Mesh.gen_rectangle"><code class="docutils literal notranslate"><span class="pre">Mesh.gen_rectangle()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/mesh.html#tensormesh.mesh.Mesh.gen_hollow_rectangle"><code class="docutils literal notranslate"><span class="pre">Mesh.gen_hollow_rectangle()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/mesh.html#tensormesh.mesh.Mesh.gen_circle"><code class="docutils literal notranslate"><span class="pre">Mesh.gen_circle()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/mesh.html#tensormesh.mesh.Mesh.gen_hollow_circle"><code class="docutils literal notranslate"><span class="pre">Mesh.gen_hollow_circle()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/mesh.html#tensormesh.mesh.Mesh.gen_L"><code class="docutils literal notranslate"><span class="pre">Mesh.gen_L()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/mesh.html#tensormesh.mesh.Mesh.gen_cube"><code class="docutils literal notranslate"><span class="pre">Mesh.gen_cube()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/mesh.html#tensormesh.mesh.Mesh.gen_hollow_cube"><code class="docutils literal notranslate"><span class="pre">Mesh.gen_hollow_cube()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/mesh.html#tensormesh.mesh.Mesh.gen_sphere"><code class="docutils literal notranslate"><span class="pre">Mesh.gen_sphere()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/mesh.html#tensormesh.mesh.Mesh.gen_hollow_sphere"><code class="docutils literal notranslate"><span class="pre">Mesh.gen_hollow_sphere()</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_reference/element.html">tensormesh.element</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../api_reference/element.html#elements">Elements</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Element"><code class="docutils literal notranslate"><span class="pre">Element</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Element.points"><code class="docutils literal notranslate"><span class="pre">Element.points</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Element.vertex"><code class="docutils literal notranslate"><span class="pre">Element.vertex</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Element.edge"><code class="docutils literal notranslate"><span class="pre">Element.edge</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Element.face"><code class="docutils literal notranslate"><span class="pre">Element.face</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Element.cell"><code class="docutils literal notranslate"><span class="pre">Element.cell</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Element.dim"><code class="docutils literal notranslate"><span class="pre">Element.dim</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Element.n_vertex"><code class="docutils literal notranslate"><span class="pre">Element.n_vertex</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Element.n_edge"><code class="docutils literal notranslate"><span class="pre">Element.n_edge</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Element.n_face"><code class="docutils literal notranslate"><span class="pre">Element.n_face</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Element.n_cell"><code class="docutils literal notranslate"><span class="pre">Element.n_cell</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Element.is_mix_facet"><code class="docutils literal notranslate"><span class="pre">Element.is_mix_facet</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Element.get_facet_type"><code class="docutils literal notranslate"><span class="pre">Element.get_facet_type()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Element.get_basis"><code class="docutils literal notranslate"><span class="pre">Element.get_basis()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Element.get_facet"><code class="docutils literal notranslate"><span class="pre">Element.get_facet()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Element.get_edge"><code class="docutils literal notranslate"><span class="pre">Element.get_edge()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Element.get_polynomial"><code class="docutils literal notranslate"><span class="pre">Element.get_polynomial()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Element.get_quadrature"><code class="docutils literal notranslate"><span class="pre">Element.get_quadrature()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Element.get_facet_quadrature"><code class="docutils literal notranslate"><span class="pre">Element.get_facet_quadrature()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Element.get_basis_fns"><code class="docutils literal notranslate"><span class="pre">Element.get_basis_fns()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Element.get_basis_grad_fns"><code class="docutils literal notranslate"><span class="pre">Element.get_basis_grad_fns()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Element.eval_cell_jacobian"><code class="docutils literal notranslate"><span class="pre">Element.eval_cell_jacobian()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Element.eval_shape_val"><code class="docutils literal notranslate"><span class="pre">Element.eval_shape_val()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Element.eval_shape_grad"><code class="docutils literal notranslate"><span class="pre">Element.eval_shape_grad()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Element.get_local_facet_mapping_fns"><code class="docutils literal notranslate"><span class="pre">Element.get_local_facet_mapping_fns()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Element.get_local_facet_mapping_grad_fns"><code class="docutils literal notranslate"><span class="pre">Element.get_local_facet_mapping_grad_fns()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Element.get_outwards_facet_normal"><code class="docutils literal notranslate"><span class="pre">Element.get_outwards_facet_normal()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Element.get_n_facet"><code class="docutils literal notranslate"><span class="pre">Element.get_n_facet()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Element.get_n_basis"><code class="docutils literal notranslate"><span class="pre">Element.get_n_basis()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Element.eval_facet_cell_jacobian"><code class="docutils literal notranslate"><span class="pre">Element.eval_facet_cell_jacobian()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Element.eval_facet_jacobian"><code class="docutils literal notranslate"><span class="pre">Element.eval_facet_jacobian()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Element.element_to_facet"><code class="docutils literal notranslate"><span class="pre">Element.element_to_facet()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Element.element_to_edge"><code class="docutils literal notranslate"><span class="pre">Element.element_to_edge()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Element.get_tri_mask"><code class="docutils literal notranslate"><span class="pre">Element.get_tri_mask()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Element.get_quad_mask"><code class="docutils literal notranslate"><span class="pre">Element.get_quad_mask()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Element.get_contour"><code class="docutils literal notranslate"><span class="pre">Element.get_contour()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Line"><code class="docutils literal notranslate"><span class="pre">Line</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Line.points"><code class="docutils literal notranslate"><span class="pre">Line.points</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Line.vertex"><code class="docutils literal notranslate"><span class="pre">Line.vertex</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Line.edge"><code class="docutils literal notranslate"><span class="pre">Line.edge</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Line.dim"><code class="docutils literal notranslate"><span class="pre">Line.dim</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Line.n_vertex"><code class="docutils literal notranslate"><span class="pre">Line.n_vertex</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Line.n_edge"><code class="docutils literal notranslate"><span class="pre">Line.n_edge</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Line.n_face"><code class="docutils literal notranslate"><span class="pre">Line.n_face</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Line.n_cell"><code class="docutils literal notranslate"><span class="pre">Line.n_cell</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Line.get_basis"><code class="docutils literal notranslate"><span class="pre">Line.get_basis()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Line.get_polynomial"><code class="docutils literal notranslate"><span class="pre">Line.get_polynomial()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Line.get_quadrature"><code class="docutils literal notranslate"><span class="pre">Line.get_quadrature()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Triangle"><code class="docutils literal notranslate"><span class="pre">Triangle</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Triangle.points"><code class="docutils literal notranslate"><span class="pre">Triangle.points</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Triangle.vertex"><code class="docutils literal notranslate"><span class="pre">Triangle.vertex</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Triangle.edge"><code class="docutils literal notranslate"><span class="pre">Triangle.edge</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Triangle.face"><code class="docutils literal notranslate"><span class="pre">Triangle.face</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Triangle.dim"><code class="docutils literal notranslate"><span class="pre">Triangle.dim</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Triangle.n_vertex"><code class="docutils literal notranslate"><span class="pre">Triangle.n_vertex</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Triangle.n_edge"><code class="docutils literal notranslate"><span class="pre">Triangle.n_edge</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Triangle.n_face"><code class="docutils literal notranslate"><span class="pre">Triangle.n_face</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Triangle.n_cell"><code class="docutils literal notranslate"><span class="pre">Triangle.n_cell</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Triangle.get_basis"><code class="docutils literal notranslate"><span class="pre">Triangle.get_basis()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Triangle.get_polynomial"><code class="docutils literal notranslate"><span class="pre">Triangle.get_polynomial()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Triangle.get_facet"><code class="docutils literal notranslate"><span class="pre">Triangle.get_facet()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Triangle.get_quadrature"><code class="docutils literal notranslate"><span class="pre">Triangle.get_quadrature()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Triangle.get_facet_quadrature"><code class="docutils literal notranslate"><span class="pre">Triangle.get_facet_quadrature()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Triangle.get_facet_type"><code class="docutils literal notranslate"><span class="pre">Triangle.get_facet_type()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Triangle.get_contour"><code class="docutils literal notranslate"><span class="pre">Triangle.get_contour()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Tetrahedron"><code class="docutils literal notranslate"><span class="pre">Tetrahedron</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Tetrahedron.points"><code class="docutils literal notranslate"><span class="pre">Tetrahedron.points</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Tetrahedron.vertex"><code class="docutils literal notranslate"><span class="pre">Tetrahedron.vertex</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Tetrahedron.edge"><code class="docutils literal notranslate"><span class="pre">Tetrahedron.edge</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Tetrahedron.face"><code class="docutils literal notranslate"><span class="pre">Tetrahedron.face</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Tetrahedron.cell"><code class="docutils literal notranslate"><span class="pre">Tetrahedron.cell</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Tetrahedron.dim"><code class="docutils literal notranslate"><span class="pre">Tetrahedron.dim</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Tetrahedron.n_vertex"><code class="docutils literal notranslate"><span class="pre">Tetrahedron.n_vertex</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Tetrahedron.n_edge"><code class="docutils literal notranslate"><span class="pre">Tetrahedron.n_edge</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Tetrahedron.n_face"><code class="docutils literal notranslate"><span class="pre">Tetrahedron.n_face</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Tetrahedron.n_cell"><code class="docutils literal notranslate"><span class="pre">Tetrahedron.n_cell</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Tetrahedron.get_basis"><code class="docutils literal notranslate"><span class="pre">Tetrahedron.get_basis()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Tetrahedron.get_polynomial"><code class="docutils literal notranslate"><span class="pre">Tetrahedron.get_polynomial()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Tetrahedron.get_quadrature"><code class="docutils literal notranslate"><span class="pre">Tetrahedron.get_quadrature()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Tetrahedron.get_facet"><code class="docutils literal notranslate"><span class="pre">Tetrahedron.get_facet()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Tetrahedron.get_facet_quadrature"><code class="docutils literal notranslate"><span class="pre">Tetrahedron.get_facet_quadrature()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Tetrahedron.get_facet_type"><code class="docutils literal notranslate"><span class="pre">Tetrahedron.get_facet_type()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Quadrilateral"><code class="docutils literal notranslate"><span class="pre">Quadrilateral</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Quadrilateral.points"><code class="docutils literal notranslate"><span class="pre">Quadrilateral.points</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Quadrilateral.vertex"><code class="docutils literal notranslate"><span class="pre">Quadrilateral.vertex</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Quadrilateral.edge"><code class="docutils literal notranslate"><span class="pre">Quadrilateral.edge</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Quadrilateral.face"><code class="docutils literal notranslate"><span class="pre">Quadrilateral.face</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Quadrilateral.dim"><code class="docutils literal notranslate"><span class="pre">Quadrilateral.dim</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Quadrilateral.n_vertex"><code class="docutils literal notranslate"><span class="pre">Quadrilateral.n_vertex</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Quadrilateral.n_edge"><code class="docutils literal notranslate"><span class="pre">Quadrilateral.n_edge</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Quadrilateral.n_face"><code class="docutils literal notranslate"><span class="pre">Quadrilateral.n_face</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Quadrilateral.n_cell"><code class="docutils literal notranslate"><span class="pre">Quadrilateral.n_cell</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Quadrilateral.get_basis"><code class="docutils literal notranslate"><span class="pre">Quadrilateral.get_basis()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Quadrilateral.get_polynomial"><code class="docutils literal notranslate"><span class="pre">Quadrilateral.get_polynomial()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Quadrilateral.get_facet"><code class="docutils literal notranslate"><span class="pre">Quadrilateral.get_facet()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Quadrilateral.get_quadrature"><code class="docutils literal notranslate"><span class="pre">Quadrilateral.get_quadrature()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Quadrilateral.get_facet_quadrature"><code class="docutils literal notranslate"><span class="pre">Quadrilateral.get_facet_quadrature()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Quadrilateral.get_facet_type"><code class="docutils literal notranslate"><span class="pre">Quadrilateral.get_facet_type()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Quadrilateral.get_coutour"><code class="docutils literal notranslate"><span class="pre">Quadrilateral.get_coutour()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Hexahedron"><code class="docutils literal notranslate"><span class="pre">Hexahedron</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Hexahedron.points"><code class="docutils literal notranslate"><span class="pre">Hexahedron.points</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Hexahedron.vertex"><code class="docutils literal notranslate"><span class="pre">Hexahedron.vertex</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Hexahedron.edge"><code class="docutils literal notranslate"><span class="pre">Hexahedron.edge</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Hexahedron.face"><code class="docutils literal notranslate"><span class="pre">Hexahedron.face</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Hexahedron.cell"><code class="docutils literal notranslate"><span class="pre">Hexahedron.cell</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Hexahedron.dim"><code class="docutils literal notranslate"><span class="pre">Hexahedron.dim</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Hexahedron.n_vertex"><code class="docutils literal notranslate"><span class="pre">Hexahedron.n_vertex</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Hexahedron.n_edge"><code class="docutils literal notranslate"><span class="pre">Hexahedron.n_edge</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Hexahedron.n_face"><code class="docutils literal notranslate"><span class="pre">Hexahedron.n_face</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Hexahedron.n_cell"><code class="docutils literal notranslate"><span class="pre">Hexahedron.n_cell</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Hexahedron.get_basis"><code class="docutils literal notranslate"><span class="pre">Hexahedron.get_basis()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Hexahedron.get_polynomial"><code class="docutils literal notranslate"><span class="pre">Hexahedron.get_polynomial()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Hexahedron.get_quadrature"><code class="docutils literal notranslate"><span class="pre">Hexahedron.get_quadrature()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Hexahedron.get_facet"><code class="docutils literal notranslate"><span class="pre">Hexahedron.get_facet()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Hexahedron.get_facet_quadrature"><code class="docutils literal notranslate"><span class="pre">Hexahedron.get_facet_quadrature()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Hexahedron.get_facet_type"><code class="docutils literal notranslate"><span class="pre">Hexahedron.get_facet_type()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Prism"><code class="docutils literal notranslate"><span class="pre">Prism</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Prism.points"><code class="docutils literal notranslate"><span class="pre">Prism.points</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Prism.vertex"><code class="docutils literal notranslate"><span class="pre">Prism.vertex</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Prism.edge"><code class="docutils literal notranslate"><span class="pre">Prism.edge</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Prism.face"><code class="docutils literal notranslate"><span class="pre">Prism.face</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Prism.cell"><code class="docutils literal notranslate"><span class="pre">Prism.cell</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Prism.dim"><code class="docutils literal notranslate"><span class="pre">Prism.dim</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Prism.n_vertex"><code class="docutils literal notranslate"><span class="pre">Prism.n_vertex</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Prism.n_edge"><code class="docutils literal notranslate"><span class="pre">Prism.n_edge</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Prism.n_face"><code class="docutils literal notranslate"><span class="pre">Prism.n_face</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Prism.n_cell"><code class="docutils literal notranslate"><span class="pre">Prism.n_cell</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Prism.is_mix_facet"><code class="docutils literal notranslate"><span class="pre">Prism.is_mix_facet</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Prism.get_basis"><code class="docutils literal notranslate"><span class="pre">Prism.get_basis()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Prism.get_polynomial"><code class="docutils literal notranslate"><span class="pre">Prism.get_polynomial()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Prism.get_quadrature"><code class="docutils literal notranslate"><span class="pre">Prism.get_quadrature()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Prism.get_facet"><code class="docutils literal notranslate"><span class="pre">Prism.get_facet()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Prism.get_facet_quadrature"><code class="docutils literal notranslate"><span class="pre">Prism.get_facet_quadrature()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Prism.get_facet_type"><code class="docutils literal notranslate"><span class="pre">Prism.get_facet_type()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Pyramid"><code class="docutils literal notranslate"><span class="pre">Pyramid</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Pyramid.points"><code class="docutils literal notranslate"><span class="pre">Pyramid.points</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Pyramid.vertex"><code class="docutils literal notranslate"><span class="pre">Pyramid.vertex</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Pyramid.edge"><code class="docutils literal notranslate"><span class="pre">Pyramid.edge</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Pyramid.face"><code class="docutils literal notranslate"><span class="pre">Pyramid.face</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Pyramid.cell"><code class="docutils literal notranslate"><span class="pre">Pyramid.cell</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Pyramid.dim"><code class="docutils literal notranslate"><span class="pre">Pyramid.dim</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Pyramid.n_vertex"><code class="docutils literal notranslate"><span class="pre">Pyramid.n_vertex</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Pyramid.n_edge"><code class="docutils literal notranslate"><span class="pre">Pyramid.n_edge</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Pyramid.n_face"><code class="docutils literal notranslate"><span class="pre">Pyramid.n_face</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Pyramid.n_cell"><code class="docutils literal notranslate"><span class="pre">Pyramid.n_cell</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Pyramid.is_mix_facet"><code class="docutils literal notranslate"><span class="pre">Pyramid.is_mix_facet</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Pyramid.get_basis"><code class="docutils literal notranslate"><span class="pre">Pyramid.get_basis()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Pyramid.get_polynomial"><code class="docutils literal notranslate"><span class="pre">Pyramid.get_polynomial()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Pyramid.get_quadrature"><code class="docutils literal notranslate"><span class="pre">Pyramid.get_quadrature()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Pyramid.get_facet"><code class="docutils literal notranslate"><span class="pre">Pyramid.get_facet()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Pyramid.get_facet_quadrature"><code class="docutils literal notranslate"><span class="pre">Pyramid.get_facet_quadrature()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.element.Pyramid.get_facet_type"><code class="docutils literal notranslate"><span class="pre">Pyramid.get_facet_type()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../api_reference/element.html#transformation">Transformation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.transformation.Transformation"><code class="docutils literal notranslate"><span class="pre">Transformation</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.transformation.Transformation.elements"><code class="docutils literal notranslate"><span class="pre">Transformation.elements</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.transformation.Transformation.points"><code class="docutils literal notranslate"><span class="pre">Transformation.points</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.transformation.Transformation.element"><code class="docutils literal notranslate"><span class="pre">Transformation.element</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.transformation.Transformation.basis_order"><code class="docutils literal notranslate"><span class="pre">Transformation.basis_order</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.transformation.Transformation.quadrature_order"><code class="docutils literal notranslate"><span class="pre">Transformation.quadrature_order</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#id0"><code class="docutils literal notranslate"><span class="pre">Transformation.elements</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#id1"><code class="docutils literal notranslate"><span class="pre">Transformation.points</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.transformation.Transformation.__init__"><code class="docutils literal notranslate"><span class="pre">Transformation.__init__()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#id2"><code class="docutils literal notranslate"><span class="pre">Transformation.element</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#id3"><code class="docutils literal notranslate"><span class="pre">Transformation.basis_order</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#id4"><code class="docutils literal notranslate"><span class="pre">Transformation.quadrature_order</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.transformation.Transformation.update_points"><code class="docutils literal notranslate"><span class="pre">Transformation.update_points()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.transformation.Transformation.dim"><code class="docutils literal notranslate"><span class="pre">Transformation.dim</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.transformation.Transformation.device"><code class="docutils literal notranslate"><span class="pre">Transformation.device</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.transformation.Transformation.dtype"><code class="docutils literal notranslate"><span class="pre">Transformation.dtype</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.transformation.Transformation.element_coords"><code class="docutils literal notranslate"><span class="pre">Transformation.element_coords</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.transformation.Transformation.n_elements"><code class="docutils literal notranslate"><span class="pre">Transformation.n_elements</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.transformation.Transformation.basis"><code class="docutils literal notranslate"><span class="pre">Transformation.basis</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.transformation.Transformation.n_basis"><code class="docutils literal notranslate"><span class="pre">Transformation.n_basis</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.transformation.Transformation.quadrature"><code class="docutils literal notranslate"><span class="pre">Transformation.quadrature</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.transformation.Transformation.n_quadrature"><code class="docutils literal notranslate"><span class="pre">Transformation.n_quadrature</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.transformation.Transformation.shape_val"><code class="docutils literal notranslate"><span class="pre">Transformation.shape_val</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.transformation.Transformation.shape_grad"><code class="docutils literal notranslate"><span class="pre">Transformation.shape_grad</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.transformation.Transformation.jacobian"><code class="docutils literal notranslate"><span class="pre">Transformation.jacobian</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.transformation.Transformation.facets"><code class="docutils literal notranslate"><span class="pre">Transformation.facets</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.transformation.Transformation.facet_quadrature"><code class="docutils literal notranslate"><span class="pre">Transformation.facet_quadrature</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.transformation.Transformation.facet_shape_val"><code class="docutils literal notranslate"><span class="pre">Transformation.facet_shape_val</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.transformation.Transformation.facet_shape_grad"><code class="docutils literal notranslate"><span class="pre">Transformation.facet_shape_grad</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.transformation.Transformation.facet_jacobian"><code class="docutils literal notranslate"><span class="pre">Transformation.facet_jacobian</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.transformation.Transformation.nanson_scale"><code class="docutils literal notranslate"><span class="pre">Transformation.nanson_scale</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.transformation.Transformation.phi"><code class="docutils literal notranslate"><span class="pre">Transformation.phi</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.transformation.Transformation.gradphi"><code class="docutils literal notranslate"><span class="pre">Transformation.gradphi</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.transformation.Transformation.J"><code class="docutils literal notranslate"><span class="pre">Transformation.J</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.transformation.Transformation.detJ"><code class="docutils literal notranslate"><span class="pre">Transformation.detJ</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.transformation.Transformation.JxW"><code class="docutils literal notranslate"><span class="pre">Transformation.JxW</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.transformation.Transformation.G"><code class="docutils literal notranslate"><span class="pre">Transformation.G</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.transformation.Transformation.detG"><code class="docutils literal notranslate"><span class="pre">Transformation.detG</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.transformation.Transformation.GxW"><code class="docutils literal notranslate"><span class="pre">Transformation.GxW</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.transformation.Transformation.F"><code class="docutils literal notranslate"><span class="pre">Transformation.F</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.transformation.Transformation.detF"><code class="docutils literal notranslate"><span class="pre">Transformation.detF</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.transformation.Transformation.FxW"><code class="docutils literal notranslate"><span class="pre">Transformation.FxW</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.transformation.Transformation.n"><code class="docutils literal notranslate"><span class="pre">Transformation.n</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.transformation.Transformation.batch_quadrature"><code class="docutils literal notranslate"><span class="pre">Transformation.batch_quadrature()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.transformation.Transformation.batch_elements_coords"><code class="docutils literal notranslate"><span class="pre">Transformation.batch_elements_coords()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.transformation.Transformation.batch_shape_val"><code class="docutils literal notranslate"><span class="pre">Transformation.batch_shape_val()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.transformation.Transformation.batch_shape_grad_jxw"><code class="docutils literal notranslate"><span class="pre">Transformation.batch_shape_grad_jxw()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../api_reference/element.html#polynomial">Polynomial</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.polynomial.Polynomial"><code class="docutils literal notranslate"><span class="pre">Polynomial</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.polynomial.Polynomial.__init__"><code class="docutils literal notranslate"><span class="pre">Polynomial.__init__()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.polynomial.Polynomial.n_vars"><code class="docutils literal notranslate"><span class="pre">Polynomial.n_vars</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.polynomial.Polynomial.n_terms"><code class="docutils literal notranslate"><span class="pre">Polynomial.n_terms</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.polynomial.Polynomial.forward"><code class="docutils literal notranslate"><span class="pre">Polynomial.forward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.polynomial.Polynomial.get_exp_terms"><code class="docutils literal notranslate"><span class="pre">Polynomial.get_exp_terms()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.polynomial.Polynomial.deriv"><code class="docutils literal notranslate"><span class="pre">Polynomial.deriv()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.polynomial.Polynomial.grad"><code class="docutils literal notranslate"><span class="pre">Polynomial.grad()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.polynomial.Polynomial.reset_coef"><code class="docutils literal notranslate"><span class="pre">Polynomial.reset_coef()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.polynomial.Polynomial.repeat"><code class="docutils literal notranslate"><span class="pre">Polynomial.repeat()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.polynomial.Polynomial.lin_exp"><code class="docutils literal notranslate"><span class="pre">Polynomial.lin_exp()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.polynomial.Polynomial.poly_exp"><code class="docutils literal notranslate"><span class="pre">Polynomial.poly_exp()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.polynomial.Polynomial.tens_exp"><code class="docutils literal notranslate"><span class="pre">Polynomial.tens_exp()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.polynomial.Polynomial.pyr_exp"><code class="docutils literal notranslate"><span class="pre">Polynomial.pyr_exp()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.polynomial.Polynomial.pri_exp"><code class="docutils literal notranslate"><span class="pre">Polynomial.pri_exp()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.polynomial.Polynomials"><code class="docutils literal notranslate"><span class="pre">Polynomials</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.polynomial.Polynomials._coef"><code class="docutils literal notranslate"><span class="pre">Polynomials._coef</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.polynomial.Polynomials._exp"><code class="docutils literal notranslate"><span class="pre">Polynomials._exp</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.polynomial.Polynomials.n_polys"><code class="docutils literal notranslate"><span class="pre">Polynomials.n_polys</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.polynomial.Polynomials.n_vars"><code class="docutils literal notranslate"><span class="pre">Polynomials.n_vars</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.polynomial.Polynomials.n_terms"><code class="docutils literal notranslate"><span class="pre">Polynomials.n_terms</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.polynomial.Polynomials.device"><code class="docutils literal notranslate"><span class="pre">Polynomials.device</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.polynomial.Polynomials.dtype"><code class="docutils literal notranslate"><span class="pre">Polynomials.dtype</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.polynomial.Polynomials.shape"><code class="docutils literal notranslate"><span class="pre">Polynomials.shape</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.polynomial.Polynomials.__init__"><code class="docutils literal notranslate"><span class="pre">Polynomials.__init__()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#id7"><code class="docutils literal notranslate"><span class="pre">Polynomials.n_polys</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#id8"><code class="docutils literal notranslate"><span class="pre">Polynomials.n_vars</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#id9"><code class="docutils literal notranslate"><span class="pre">Polynomials.n_terms</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.polynomial.Polynomials.numel"><code class="docutils literal notranslate"><span class="pre">Polynomials.numel()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#id10"><code class="docutils literal notranslate"><span class="pre">Polynomials.shape</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.polynomial.Polynomials.ndim"><code class="docutils literal notranslate"><span class="pre">Polynomials.ndim</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#id11"><code class="docutils literal notranslate"><span class="pre">Polynomials.device</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#id12"><code class="docutils literal notranslate"><span class="pre">Polynomials.dtype</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.polynomial.Polynomials.dim"><code class="docutils literal notranslate"><span class="pre">Polynomials.dim()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.polynomial.Polynomials.forward"><code class="docutils literal notranslate"><span class="pre">Polynomials.forward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.polynomial.Polynomials.get_exp_terms"><code class="docutils literal notranslate"><span class="pre">Polynomials.get_exp_terms()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.polynomial.Polynomials.apply_coefficient"><code class="docutils literal notranslate"><span class="pre">Polynomials.apply_coefficient()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.polynomial.Polynomials.map"><code class="docutils literal notranslate"><span class="pre">Polynomials.map()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.polynomial.Polynomials.map_exp_terms"><code class="docutils literal notranslate"><span class="pre">Polynomials.map_exp_terms()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.polynomial.Polynomials.reshape"><code class="docutils literal notranslate"><span class="pre">Polynomials.reshape()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.polynomial.Polynomials.transpose"><code class="docutils literal notranslate"><span class="pre">Polynomials.transpose()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.polynomial.Polynomials.deriv"><code class="docutils literal notranslate"><span class="pre">Polynomials.deriv()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.polynomial.Polynomials.grad"><code class="docutils literal notranslate"><span class="pre">Polynomials.grad()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.polynomial.Polynomials.reset_coef"><code class="docutils literal notranslate"><span class="pre">Polynomials.reset_coef()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.polynomial.Polynomials.repeat"><code class="docutils literal notranslate"><span class="pre">Polynomials.repeat()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.polynomial.Polynomials.stack"><code class="docutils literal notranslate"><span class="pre">Polynomials.stack()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../api_reference/element.html#module-tensormesh.element.basis">Basis</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.basis.lin_linspace"><code class="docutils literal notranslate"><span class="pre">lin_linspace()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.basis.quad_linspace"><code class="docutils literal notranslate"><span class="pre">quad_linspace()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.basis.tri_linspace"><code class="docutils literal notranslate"><span class="pre">tri_linspace()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.basis.hex_linspace"><code class="docutils literal notranslate"><span class="pre">hex_linspace()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.basis.tet_linspace"><code class="docutils literal notranslate"><span class="pre">tet_linspace()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.basis.pyr_linspace"><code class="docutils literal notranslate"><span class="pre">pyr_linspace()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.basis.pri_linspace"><code class="docutils literal notranslate"><span class="pre">pri_linspace()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.basis.lin_basis"><code class="docutils literal notranslate"><span class="pre">lin_basis()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.basis.tri_basis"><code class="docutils literal notranslate"><span class="pre">tri_basis()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.basis.quad_basis"><code class="docutils literal notranslate"><span class="pre">quad_basis()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.basis.tet_basis"><code class="docutils literal notranslate"><span class="pre">tet_basis()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.basis.hex_basis"><code class="docutils literal notranslate"><span class="pre">hex_basis()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.basis.pyr_basis"><code class="docutils literal notranslate"><span class="pre">pyr_basis()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.basis.pri_basis"><code class="docutils literal notranslate"><span class="pre">pri_basis()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.basis.accumulate_range"><code class="docutils literal notranslate"><span class="pre">accumulate_range()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.basis.index_reverse_mapping"><code class="docutils literal notranslate"><span class="pre">index_reverse_mapping()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.basis.facet_basis_index_2d"><code class="docutils literal notranslate"><span class="pre">facet_basis_index_2d()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.basis.tet_facet_basis_index"><code class="docutils literal notranslate"><span class="pre">tet_facet_basis_index()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.basis.hex_facet_basis_index"><code class="docutils literal notranslate"><span class="pre">hex_facet_basis_index()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.basis.mix_facet_basis_index"><code class="docutils literal notranslate"><span class="pre">mix_facet_basis_index()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.basis.edge_index"><code class="docutils literal notranslate"><span class="pre">edge_index()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../api_reference/element.html#module-tensormesh.element.quadrature">Quadrature</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.quadrature.lin_quadrature"><code class="docutils literal notranslate"><span class="pre">lin_quadrature()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.quadrature.tri_quadrature"><code class="docutils literal notranslate"><span class="pre">tri_quadrature()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.quadrature.tet_quadrature"><code class="docutils literal notranslate"><span class="pre">tet_quadrature()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.quadrature.quad_quadrature"><code class="docutils literal notranslate"><span class="pre">quad_quadrature()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.quadrature.hex_quadrature"><code class="docutils literal notranslate"><span class="pre">hex_quadrature()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.quadrature.pyr_quadrature"><code class="docutils literal notranslate"><span class="pre">pyr_quadrature()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.quadrature.pri_quadrature"><code class="docutils literal notranslate"><span class="pre">pri_quadrature()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.quadrature.facet_quadrature_2d"><code class="docutils literal notranslate"><span class="pre">facet_quadrature_2d()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.quadrature.tet_facet_quadrature"><code class="docutils literal notranslate"><span class="pre">tet_facet_quadrature()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.quadrature.hex_facet_quadrature"><code class="docutils literal notranslate"><span class="pre">hex_facet_quadrature()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.quadrature.mix_facet_quadrature_3d"><code class="docutils literal notranslate"><span class="pre">mix_facet_quadrature_3d()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../api_reference/element.html#module-tensormesh.element.normal">Normal</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.normal.outwards_normal_2d"><code class="docutils literal notranslate"><span class="pre">outwards_normal_2d()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/element.html#tensormesh.element.normal.outwards_normal_3d"><code class="docutils literal notranslate"><span class="pre">outwards_normal_3d()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_reference/assemble.html">tensormesh.assemble</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../api_reference/assemble.html#element-assembler">Element Assembler</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/assemble.html#tensormesh.assemble.element_assembler.ElementAssembler"><code class="docutils literal notranslate"><span class="pre">ElementAssembler</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/assemble.html#tensormesh.assemble.element_assembler.ElementAssembler.quadrature_weights"><code class="docutils literal notranslate"><span class="pre">ElementAssembler.quadrature_weights</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/assemble.html#tensormesh.assemble.element_assembler.ElementAssembler.quadrature_points"><code class="docutils literal notranslate"><span class="pre">ElementAssembler.quadrature_points</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/assemble.html#tensormesh.assemble.element_assembler.ElementAssembler.shape_val"><code class="docutils literal notranslate"><span class="pre">ElementAssembler.shape_val</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/assemble.html#tensormesh.assemble.element_assembler.ElementAssembler.projector"><code class="docutils literal notranslate"><span class="pre">ElementAssembler.projector</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/assemble.html#tensormesh.assemble.element_assembler.ElementAssembler.elements"><code class="docutils literal notranslate"><span class="pre">ElementAssembler.elements</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/assemble.html#tensormesh.assemble.element_assembler.ElementAssembler.edges"><code class="docutils literal notranslate"><span class="pre">ElementAssembler.edges</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/assemble.html#tensormesh.assemble.element_assembler.ElementAssembler.n_points"><code class="docutils literal notranslate"><span class="pre">ElementAssembler.n_points</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/assemble.html#tensormesh.assemble.element_assembler.ElementAssembler.dimension"><code class="docutils literal notranslate"><span class="pre">ElementAssembler.dimension</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/assemble.html#tensormesh.assemble.element_assembler.ElementAssembler.element_types"><code class="docutils literal notranslate"><span class="pre">ElementAssembler.element_types</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/assemble.html#id0"><code class="docutils literal notranslate"><span class="pre">ElementAssembler.edges</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/assemble.html#tensormesh.assemble.element_assembler.ElementAssembler.__init__"><code class="docutils literal notranslate"><span class="pre">ElementAssembler.__init__()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/assemble.html#id1"><code class="docutils literal notranslate"><span class="pre">ElementAssembler.projector</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/assemble.html#tensormesh.assemble.element_assembler.ElementAssembler.transformation"><code class="docutils literal notranslate"><span class="pre">ElementAssembler.transformation</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/assemble.html#id2"><code class="docutils literal notranslate"><span class="pre">ElementAssembler.elements</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/assemble.html#id3"><code class="docutils literal notranslate"><span class="pre">ElementAssembler.dimension</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/assemble.html#id4"><code class="docutils literal notranslate"><span class="pre">ElementAssembler.element_types</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/assemble.html#id5"><code class="docutils literal notranslate"><span class="pre">ElementAssembler.n_points</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/assemble.html#tensormesh.assemble.element_assembler.ElementAssembler.device"><code class="docutils literal notranslate"><span class="pre">ElementAssembler.device</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/assemble.html#tensormesh.assemble.element_assembler.ElementAssembler.dtype"><code class="docutils literal notranslate"><span class="pre">ElementAssembler.dtype</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/assemble.html#tensormesh.assemble.element_assembler.ElementAssembler.type"><code class="docutils literal notranslate"><span class="pre">ElementAssembler.type()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/assemble.html#tensormesh.assemble.element_assembler.ElementAssembler.forward"><code class="docutils literal notranslate"><span class="pre">ElementAssembler.forward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/assemble.html#tensormesh.assemble.element_assembler.ElementAssembler.from_assembler"><code class="docutils literal notranslate"><span class="pre">ElementAssembler.from_assembler()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/assemble.html#tensormesh.assemble.element_assembler.ElementAssembler.from_mesh"><code class="docutils literal notranslate"><span class="pre">ElementAssembler.from_mesh()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../api_reference/assemble.html#facet-assembler">Facet Assembler</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api_reference/assemble.html#node-assembler">Node Assembler</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/assemble.html#tensormesh.assemble.node_assembler.NodeAssembler"><code class="docutils literal notranslate"><span class="pre">NodeAssembler</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/assemble.html#tensormesh.assemble.node_assembler.NodeAssembler.quadrature_weights"><code class="docutils literal notranslate"><span class="pre">NodeAssembler.quadrature_weights</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/assemble.html#tensormesh.assemble.node_assembler.NodeAssembler.quadrature_points"><code class="docutils literal notranslate"><span class="pre">NodeAssembler.quadrature_points</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/assemble.html#tensormesh.assemble.node_assembler.NodeAssembler.shape_val"><code class="docutils literal notranslate"><span class="pre">NodeAssembler.shape_val</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/assemble.html#tensormesh.assemble.node_assembler.NodeAssembler.projector"><code class="docutils literal notranslate"><span class="pre">NodeAssembler.projector</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/assemble.html#tensormesh.assemble.node_assembler.NodeAssembler.elements"><code class="docutils literal notranslate"><span class="pre">NodeAssembler.elements</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/assemble.html#tensormesh.assemble.node_assembler.NodeAssembler.n_points"><code class="docutils literal notranslate"><span class="pre">NodeAssembler.n_points</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/assemble.html#tensormesh.assemble.node_assembler.NodeAssembler.dimension"><code class="docutils literal notranslate"><span class="pre">NodeAssembler.dimension</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/assemble.html#tensormesh.assemble.node_assembler.NodeAssembler.element_types"><code class="docutils literal notranslate"><span class="pre">NodeAssembler.element_types</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/assemble.html#tensormesh.assemble.node_assembler.NodeAssembler.__init__"><code class="docutils literal notranslate"><span class="pre">NodeAssembler.__init__()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/assemble.html#id6"><code class="docutils literal notranslate"><span class="pre">NodeAssembler.projector</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/assemble.html#tensormesh.assemble.node_assembler.NodeAssembler.transformation"><code class="docutils literal notranslate"><span class="pre">NodeAssembler.transformation</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/assemble.html#id7"><code class="docutils literal notranslate"><span class="pre">NodeAssembler.elements</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/assemble.html#id8"><code class="docutils literal notranslate"><span class="pre">NodeAssembler.dimension</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/assemble.html#id9"><code class="docutils literal notranslate"><span class="pre">NodeAssembler.element_types</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/assemble.html#id10"><code class="docutils literal notranslate"><span class="pre">NodeAssembler.n_points</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/assemble.html#tensormesh.assemble.node_assembler.NodeAssembler.device"><code class="docutils literal notranslate"><span class="pre">NodeAssembler.device</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/assemble.html#tensormesh.assemble.node_assembler.NodeAssembler.dtype"><code class="docutils literal notranslate"><span class="pre">NodeAssembler.dtype</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/assemble.html#tensormesh.assemble.node_assembler.NodeAssembler.type"><code class="docutils literal notranslate"><span class="pre">NodeAssembler.type()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/assemble.html#tensormesh.assemble.node_assembler.NodeAssembler.forward"><code class="docutils literal notranslate"><span class="pre">NodeAssembler.forward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/assemble.html#tensormesh.assemble.node_assembler.NodeAssembler.from_assembler"><code class="docutils literal notranslate"><span class="pre">NodeAssembler.from_assembler()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/assemble.html#tensormesh.assemble.node_assembler.NodeAssembler.from_elements"><code class="docutils literal notranslate"><span class="pre">NodeAssembler.from_elements()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/assemble.html#tensormesh.assemble.node_assembler.NodeAssembler.from_mesh"><code class="docutils literal notranslate"><span class="pre">NodeAssembler.from_mesh()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../api_reference/assemble.html#built-in-assemblers">Built-in Assemblers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/assemble.html#tensormesh.assemble.builtin.LaplaceElementAssembler"><code class="docutils literal notranslate"><span class="pre">LaplaceElementAssembler</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/assemble.html#tensormesh.assemble.builtin.LaplaceElementAssembler.forward"><code class="docutils literal notranslate"><span class="pre">LaplaceElementAssembler.forward()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/assemble.html#tensormesh.assemble.builtin.MassElementAssembler"><code class="docutils literal notranslate"><span class="pre">MassElementAssembler</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/assemble.html#tensormesh.assemble.builtin.MassElementAssembler.forward"><code class="docutils literal notranslate"><span class="pre">MassElementAssembler.forward()</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_reference/sparse.html">tensormesh.sparse</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../api_reference/sparse.html#sparsematirx">SparseMatirx</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/sparse.html#tensormesh.sparse.SparseMatrix"><code class="docutils literal notranslate"><span class="pre">SparseMatrix</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/sparse.html#tensormesh.sparse.SparseMatrix.edata"><code class="docutils literal notranslate"><span class="pre">SparseMatrix.edata</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/sparse.html#tensormesh.sparse.SparseMatrix.row"><code class="docutils literal notranslate"><span class="pre">SparseMatrix.row</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/sparse.html#tensormesh.sparse.SparseMatrix.col"><code class="docutils literal notranslate"><span class="pre">SparseMatrix.col</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/sparse.html#tensormesh.sparse.SparseMatrix.shape"><code class="docutils literal notranslate"><span class="pre">SparseMatrix.shape</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/sparse.html#tensormesh.sparse.SparseMatrix.hash_layout"><code class="docutils literal notranslate"><span class="pre">SparseMatrix.hash_layout</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/sparse.html#id0"><code class="docutils literal notranslate"><span class="pre">SparseMatrix.edata</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/sparse.html#id1"><code class="docutils literal notranslate"><span class="pre">SparseMatrix.row</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/sparse.html#id2"><code class="docutils literal notranslate"><span class="pre">SparseMatrix.col</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/sparse.html#tensormesh.sparse.SparseMatrix.__init__"><code class="docutils literal notranslate"><span class="pre">SparseMatrix.__init__()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/sparse.html#id3"><code class="docutils literal notranslate"><span class="pre">SparseMatrix.shape</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/sparse.html#tensormesh.sparse.SparseMatrix.layout_hash"><code class="docutils literal notranslate"><span class="pre">SparseMatrix.layout_hash</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/sparse.html#tensormesh.sparse.SparseMatrix.edges"><code class="docutils literal notranslate"><span class="pre">SparseMatrix.edges</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/sparse.html#tensormesh.sparse.SparseMatrix.elementwise_operation"><code class="docutils literal notranslate"><span class="pre">SparseMatrix.elementwise_operation()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/sparse.html#tensormesh.sparse.SparseMatrix.solve"><code class="docutils literal notranslate"><span class="pre">SparseMatrix.solve()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/sparse.html#tensormesh.sparse.SparseMatrix.requires_grad_"><code class="docutils literal notranslate"><span class="pre">SparseMatrix.requires_grad_()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/sparse.html#tensormesh.sparse.SparseMatrix.transpose"><code class="docutils literal notranslate"><span class="pre">SparseMatrix.transpose()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/sparse.html#tensormesh.sparse.SparseMatrix.sqrt"><code class="docutils literal notranslate"><span class="pre">SparseMatrix.sqrt()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/sparse.html#tensormesh.sparse.SparseMatrix.reciprocal"><code class="docutils literal notranslate"><span class="pre">SparseMatrix.reciprocal()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/sparse.html#tensormesh.sparse.SparseMatrix.degree"><code class="docutils literal notranslate"><span class="pre">SparseMatrix.degree()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/sparse.html#tensormesh.sparse.SparseMatrix.sum"><code class="docutils literal notranslate"><span class="pre">SparseMatrix.sum()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/sparse.html#tensormesh.sparse.SparseMatrix.clone"><code class="docutils literal notranslate"><span class="pre">SparseMatrix.clone()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/sparse.html#tensormesh.sparse.SparseMatrix.T"><code class="docutils literal notranslate"><span class="pre">SparseMatrix.T</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/sparse.html#tensormesh.sparse.SparseMatrix.requires_grad"><code class="docutils literal notranslate"><span class="pre">SparseMatrix.requires_grad</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/sparse.html#tensormesh.sparse.SparseMatrix.dtype"><code class="docutils literal notranslate"><span class="pre">SparseMatrix.dtype</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/sparse.html#tensormesh.sparse.SparseMatrix.device"><code class="docutils literal notranslate"><span class="pre">SparseMatrix.device</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/sparse.html#tensormesh.sparse.SparseMatrix.grad"><code class="docutils literal notranslate"><span class="pre">SparseMatrix.grad</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/sparse.html#tensormesh.sparse.SparseMatrix.grad_fn"><code class="docutils literal notranslate"><span class="pre">SparseMatrix.grad_fn</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/sparse.html#tensormesh.sparse.SparseMatrix.nnz"><code class="docutils literal notranslate"><span class="pre">SparseMatrix.nnz</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/sparse.html#tensormesh.sparse.SparseMatrix.layout_mask"><code class="docutils literal notranslate"><span class="pre">SparseMatrix.layout_mask</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/sparse.html#tensormesh.sparse.SparseMatrix.type"><code class="docutils literal notranslate"><span class="pre">SparseMatrix.type()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/sparse.html#tensormesh.sparse.SparseMatrix.detach"><code class="docutils literal notranslate"><span class="pre">SparseMatrix.detach()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/sparse.html#tensormesh.sparse.SparseMatrix.to_scipy_coo"><code class="docutils literal notranslate"><span class="pre">SparseMatrix.to_scipy_coo()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/sparse.html#tensormesh.sparse.SparseMatrix.to_sparse_coo"><code class="docutils literal notranslate"><span class="pre">SparseMatrix.to_sparse_coo()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/sparse.html#tensormesh.sparse.SparseMatrix.to_dense"><code class="docutils literal notranslate"><span class="pre">SparseMatrix.to_dense()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/sparse.html#tensormesh.sparse.SparseMatrix.has_same_layout"><code class="docutils literal notranslate"><span class="pre">SparseMatrix.has_same_layout()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/sparse.html#tensormesh.sparse.SparseMatrix.from_scipy_coo"><code class="docutils literal notranslate"><span class="pre">SparseMatrix.from_scipy_coo()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/sparse.html#tensormesh.sparse.SparseMatrix.from_sparse_coo"><code class="docutils literal notranslate"><span class="pre">SparseMatrix.from_sparse_coo()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/sparse.html#tensormesh.sparse.SparseMatrix.from_block_coo"><code class="docutils literal notranslate"><span class="pre">SparseMatrix.from_block_coo()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/sparse.html#tensormesh.sparse.SparseMatrix.from_dense"><code class="docutils literal notranslate"><span class="pre">SparseMatrix.from_dense()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/sparse.html#tensormesh.sparse.SparseMatrix.random"><code class="docutils literal notranslate"><span class="pre">SparseMatrix.random()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/sparse.html#tensormesh.sparse.SparseMatrix.random_layout"><code class="docutils literal notranslate"><span class="pre">SparseMatrix.random_layout()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/sparse.html#tensormesh.sparse.SparseMatrix.random_from_layout"><code class="docutils literal notranslate"><span class="pre">SparseMatrix.random_from_layout()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/sparse.html#tensormesh.sparse.SparseMatrix.eye"><code class="docutils literal notranslate"><span class="pre">SparseMatrix.eye()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/sparse.html#tensormesh.sparse.SparseMatrix.full"><code class="docutils literal notranslate"><span class="pre">SparseMatrix.full()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/sparse.html#tensormesh.sparse.SparseMatrix.combine_vector"><code class="docutils literal notranslate"><span class="pre">SparseMatrix.combine_vector()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/sparse.html#tensormesh.sparse.SparseMatrix.combine_matrix"><code class="docutils literal notranslate"><span class="pre">SparseMatrix.combine_matrix()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/sparse.html#tensormesh.sparse.SparseMatrix.combine"><code class="docutils literal notranslate"><span class="pre">SparseMatrix.combine()</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_reference/operator.html">tensormesh.operator</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../api_reference/operator.html#condenser">Condenser</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/operator.html#tensormesh.operator.Condenser"><code class="docutils literal notranslate"><span class="pre">Condenser</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/operator.html#tensormesh.operator.Condenser.dirichlet_mask"><code class="docutils literal notranslate"><span class="pre">Condenser.dirichlet_mask</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/operator.html#tensormesh.operator.Condenser.dirichlet_value"><code class="docutils literal notranslate"><span class="pre">Condenser.dirichlet_value</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/operator.html#tensormesh.operator.Condenser.__init__"><code class="docutils literal notranslate"><span class="pre">Condenser.__init__()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/operator.html#id0"><code class="docutils literal notranslate"><span class="pre">Condenser.dirichlet_mask</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/operator.html#id1"><code class="docutils literal notranslate"><span class="pre">Condenser.dirichlet_value</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/operator.html#tensormesh.operator.Condenser.inner_row"><code class="docutils literal notranslate"><span class="pre">Condenser.inner_row</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/operator.html#tensormesh.operator.Condenser.inner_col"><code class="docutils literal notranslate"><span class="pre">Condenser.inner_col</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/operator.html#tensormesh.operator.Condenser.ou2in_row"><code class="docutils literal notranslate"><span class="pre">Condenser.ou2in_row</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/operator.html#tensormesh.operator.Condenser.ou2in_col"><code class="docutils literal notranslate"><span class="pre">Condenser.ou2in_col</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/operator.html#tensormesh.operator.Condenser.is_inner_edge"><code class="docutils literal notranslate"><span class="pre">Condenser.is_inner_edge</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/operator.html#tensormesh.operator.Condenser.is_ou2in_edge"><code class="docutils literal notranslate"><span class="pre">Condenser.is_ou2in_edge</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/operator.html#tensormesh.operator.Condenser.layout_hash"><code class="docutils literal notranslate"><span class="pre">Condenser.layout_hash</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/operator.html#tensormesh.operator.Condenser.K_ou2in"><code class="docutils literal notranslate"><span class="pre">Condenser.K_ou2in</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/operator.html#tensormesh.operator.Condenser.condense_rhs"><code class="docutils literal notranslate"><span class="pre">Condenser.condense_rhs()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/operator.html#tensormesh.operator.Condenser.recover"><code class="docutils literal notranslate"><span class="pre">Condenser.recover()</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_reference/ode.html">tensormesh.ode</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../api_reference/ode.html#runge-kutta-methods">Runge-Kutta methods</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../api_reference/ode.html#built-in-methods">Built-in Methods</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/ode.html#tensormesh.ode.ExplicitRungeKutta"><code class="docutils literal notranslate"><span class="pre">ExplicitRungeKutta</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/ode.html#tensormesh.ode.ExplicitRungeKutta.__init__"><code class="docutils literal notranslate"><span class="pre">ExplicitRungeKutta.__init__()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/ode.html#tensormesh.ode.ExplicitRungeKutta.forward"><code class="docutils literal notranslate"><span class="pre">ExplicitRungeKutta.forward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/ode.html#tensormesh.ode.ExplicitRungeKutta.step"><code class="docutils literal notranslate"><span class="pre">ExplicitRungeKutta.step()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/ode.html#tensormesh.ode.ImplicitLinearRungeKutta"><code class="docutils literal notranslate"><span class="pre">ImplicitLinearRungeKutta</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/ode.html#tensormesh.ode.ImplicitLinearRungeKutta.__init__"><code class="docutils literal notranslate"><span class="pre">ImplicitLinearRungeKutta.__init__()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/ode.html#tensormesh.ode.ImplicitLinearRungeKutta.forward_M"><code class="docutils literal notranslate"><span class="pre">ImplicitLinearRungeKutta.forward_M()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/ode.html#tensormesh.ode.ImplicitLinearRungeKutta.forward_A"><code class="docutils literal notranslate"><span class="pre">ImplicitLinearRungeKutta.forward_A()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/ode.html#tensormesh.ode.ImplicitLinearRungeKutta.forward_B"><code class="docutils literal notranslate"><span class="pre">ImplicitLinearRungeKutta.forward_B()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/ode.html#tensormesh.ode.ImplicitLinearRungeKutta.pre_solve_lhs"><code class="docutils literal notranslate"><span class="pre">ImplicitLinearRungeKutta.pre_solve_lhs()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/ode.html#tensormesh.ode.ImplicitLinearRungeKutta.pre_solve_rhs"><code class="docutils literal notranslate"><span class="pre">ImplicitLinearRungeKutta.pre_solve_rhs()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/ode.html#tensormesh.ode.ImplicitLinearRungeKutta.post_solve"><code class="docutils literal notranslate"><span class="pre">ImplicitLinearRungeKutta.post_solve()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/ode.html#tensormesh.ode.ImplicitLinearRungeKutta.step"><code class="docutils literal notranslate"><span class="pre">ImplicitLinearRungeKutta.step()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/ode.html#tensormesh.ode.builtin.ExplicitEuler"><code class="docutils literal notranslate"><span class="pre">ExplicitEuler</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/ode.html#tensormesh.ode.builtin.ExplicitEuler.__init__"><code class="docutils literal notranslate"><span class="pre">ExplicitEuler.__init__()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/ode.html#tensormesh.ode.builtin.ImplicitLinearEuler"><code class="docutils literal notranslate"><span class="pre">ImplicitLinearEuler</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/ode.html#tensormesh.ode.builtin.ImplicitLinearEuler.__init__"><code class="docutils literal notranslate"><span class="pre">ImplicitLinearEuler.__init__()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/ode.html#tensormesh.ode.builtin.MidPointLinearEuler"><code class="docutils literal notranslate"><span class="pre">MidPointLinearEuler</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/ode.html#tensormesh.ode.builtin.MidPointLinearEuler.__init__"><code class="docutils literal notranslate"><span class="pre">MidPointLinearEuler.__init__()</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_reference/functional.html">tensormesh.functional</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../api_reference/functional.html#module-tensormesh.functional.ops">ops</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/functional.html#tensormesh.functional.ops.sym"><code class="docutils literal notranslate"><span class="pre">sym()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/functional.html#tensormesh.functional.ops.skew"><code class="docutils literal notranslate"><span class="pre">skew()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/functional.html#tensormesh.functional.ops.sqrt"><code class="docutils literal notranslate"><span class="pre">sqrt()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/functional.html#tensormesh.functional.ops.divide"><code class="docutils literal notranslate"><span class="pre">divide()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../api_reference/functional.html#module-tensormesh.functional.elasticity">elasticity</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/functional.html#tensormesh.functional.elasticity.strain"><code class="docutils literal notranslate"><span class="pre">strain()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/functional.html#tensormesh.functional.elasticity.isotropic_stress"><code class="docutils literal notranslate"><span class="pre">isotropic_stress()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/functional.html#tensormesh.functional.elasticity.deviatoric_stress"><code class="docutils literal notranslate"><span class="pre">deviatoric_stress()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/functional.html#tensormesh.functional.elasticity.deviatoric_stress_norm"><code class="docutils literal notranslate"><span class="pre">deviatoric_stress_norm()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/functional.html#tensormesh.functional.elasticity.voigt_shape_grad"><code class="docutils literal notranslate"><span class="pre">voigt_shape_grad()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/functional.html#tensormesh.functional.elasticity.voigt_stiffness"><code class="docutils literal notranslate"><span class="pre">voigt_stiffness()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/functional.html#tensormesh.functional.elasticity.voigt_shape_val"><code class="docutils literal notranslate"><span class="pre">voigt_shape_val()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/functional.html#tensormesh.functional.elasticity.voigt_C"><code class="docutils literal notranslate"><span class="pre">voigt_C()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/functional.html#tensormesh.functional.elasticity.voigt_B"><code class="docutils literal notranslate"><span class="pre">voigt_B()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/functional.html#tensormesh.functional.elasticity.voigt_N"><code class="docutils literal notranslate"><span class="pre">voigt_N()</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../api_reference/functional.html#module-tensormesh.functional.plastic">plastic</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/functional.html#tensormesh.functional.plastic.update_plastic_stress"><code class="docutils literal notranslate"><span class="pre">update_plastic_stress()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_reference/nn.html">NN</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../api_reference/nn.html#bufferutils">BufferUtils</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/nn.html#tensormesh.nn.BufferDict"><code class="docutils literal notranslate"><span class="pre">BufferDict</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/nn.html#tensormesh.nn.BufferDict.__init__"><code class="docutils literal notranslate"><span class="pre">BufferDict.__init__()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/nn.html#tensormesh.nn.BufferDict.as_parameter"><code class="docutils literal notranslate"><span class="pre">BufferDict.as_parameter()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/nn.html#tensormesh.nn.BufferDict.as_buffer"><code class="docutils literal notranslate"><span class="pre">BufferDict.as_buffer()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/nn.html#tensormesh.nn.BufferDict.keys"><code class="docutils literal notranslate"><span class="pre">BufferDict.keys()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/nn.html#tensormesh.nn.BufferDict.items"><code class="docutils literal notranslate"><span class="pre">BufferDict.items()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/nn.html#tensormesh.nn.BufferDict.values"><code class="docutils literal notranslate"><span class="pre">BufferDict.values()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/nn.html#tensormesh.nn.BufferDict.is_floating_point"><code class="docutils literal notranslate"><span class="pre">BufferDict.is_floating_point()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/nn.html#tensormesh.nn.BufferDict.is_complex"><code class="docutils literal notranslate"><span class="pre">BufferDict.is_complex()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/nn.html#tensormesh.nn.BufferDict.dtype"><code class="docutils literal notranslate"><span class="pre">BufferDict.dtype</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/nn.html#tensormesh.nn.BufferDict.device"><code class="docutils literal notranslate"><span class="pre">BufferDict.device</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/nn.html#tensormesh.nn.BufferDict.to_dict"><code class="docutils literal notranslate"><span class="pre">BufferDict.to_dict()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/nn.html#tensormesh.nn.BufferDict.clone"><code class="docutils literal notranslate"><span class="pre">BufferDict.clone()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/nn.html#tensormesh.nn.BufferList"><code class="docutils literal notranslate"><span class="pre">BufferList</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/nn.html#tensormesh.nn.BufferList.__init__"><code class="docutils literal notranslate"><span class="pre">BufferList.__init__()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/nn.html#tensormesh.nn.BufferList.as_parameter"><code class="docutils literal notranslate"><span class="pre">BufferList.as_parameter()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/nn.html#tensormesh.nn.BufferList.as_buffer"><code class="docutils literal notranslate"><span class="pre">BufferList.as_buffer()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/nn.html#tensormesh.nn.BufferList.append"><code class="docutils literal notranslate"><span class="pre">BufferList.append()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/nn.html#tensormesh.nn.BufferList.insert"><code class="docutils literal notranslate"><span class="pre">BufferList.insert()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/nn.html#tensormesh.nn.BufferList.pop"><code class="docutils literal notranslate"><span class="pre">BufferList.pop()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/nn.html#tensormesh.nn.BufferList.item"><code class="docutils literal notranslate"><span class="pre">BufferList.item()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/nn.html#tensormesh.nn.BufferList.is_floating_point"><code class="docutils literal notranslate"><span class="pre">BufferList.is_floating_point()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/nn.html#tensormesh.nn.BufferList.is_complex"><code class="docutils literal notranslate"><span class="pre">BufferList.is_complex()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/nn.html#tensormesh.nn.BufferList.dtype"><code class="docutils literal notranslate"><span class="pre">BufferList.dtype</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/nn.html#tensormesh.nn.BufferList.device"><code class="docutils literal notranslate"><span class="pre">BufferList.device</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/nn.html#tensormesh.nn.BufferList.to_list"><code class="docutils literal notranslate"><span class="pre">BufferList.to_list()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/nn.html#tensormesh.nn.BufferList.clone"><code class="docutils literal notranslate"><span class="pre">BufferList.clone()</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_reference/visualization.html">visualization</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../api_reference/visualization.html#module-tensormesh.visualization.draw_graph">Draw Facet</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/visualization.html#tensormesh.visualization.draw_graph.draw_graph"><code class="docutils literal notranslate"><span class="pre">draw_graph()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/visualization.html#tensormesh.visualization.draw_mesh.draw_mesh"><code class="docutils literal notranslate"><span class="pre">draw_mesh()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/visualization.html#tensormesh.visualization.draw_facet.draw_facet_2d"><code class="docutils literal notranslate"><span class="pre">draw_facet_2d()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/visualization.html#tensormesh.visualization.draw_facet.draw_face"><code class="docutils literal notranslate"><span class="pre">draw_face()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/visualization.html#tensormesh.visualization.draw_element_value.draw_element_value_2d_tri"><code class="docutils literal notranslate"><span class="pre">draw_element_value_2d_tri()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/visualization.html#tensormesh.visualization.draw_element_value.draw_element_value_2d"><code class="docutils literal notranslate"><span class="pre">draw_element_value_2d()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/visualization.html#tensormesh.visualization.draw_element_value.update_element_value_2d_tri"><code class="docutils literal notranslate"><span class="pre">update_element_value_2d_tri()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/visualization.html#tensormesh.visualization.draw_element_value.update_element_value_2d"><code class="docutils literal notranslate"><span class="pre">update_element_value_2d()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/visualization.html#tensormesh.visualization.draw_element_value.draw_element_value_3d"><code class="docutils literal notranslate"><span class="pre">draw_element_value_3d()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/visualization.html#tensormesh.visualization.draw_element_value.update_element_value_3d"><code class="docutils literal notranslate"><span class="pre">update_element_value_3d()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/visualization.html#tensormesh.visualization.draw_element_value.draw_element_value"><code class="docutils literal notranslate"><span class="pre">draw_element_value()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/visualization.html#tensormesh.visualization.draw_element_value.update_element_value"><code class="docutils literal notranslate"><span class="pre">update_element_value()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/visualization.html#tensormesh.visualization.draw_point_value.draw_point_value_2d_tri_gouraud"><code class="docutils literal notranslate"><span class="pre">draw_point_value_2d_tri_gouraud()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/visualization.html#tensormesh.visualization.draw_point_value.update_point_value_2d_tri_gouraud"><code class="docutils literal notranslate"><span class="pre">update_point_value_2d_tri_gouraud()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/visualization.html#tensormesh.visualization.draw_point_value.draw_point_value_2d_interpolation"><code class="docutils literal notranslate"><span class="pre">draw_point_value_2d_interpolation()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/visualization.html#tensormesh.visualization.draw_point_value.update_point_value_2d_interpolation"><code class="docutils literal notranslate"><span class="pre">update_point_value_2d_interpolation()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/visualization.html#tensormesh.visualization.draw_point_value.draw_point_value_2d"><code class="docutils literal notranslate"><span class="pre">draw_point_value_2d()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/visualization.html#tensormesh.visualization.draw_point_value.update_point_value_2d"><code class="docutils literal notranslate"><span class="pre">update_point_value_2d()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/visualization.html#tensormesh.visualization.draw_point_value.draw_point_value_3d_interpolation"><code class="docutils literal notranslate"><span class="pre">draw_point_value_3d_interpolation()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/visualization.html#tensormesh.visualization.draw_point_value.update_point_value_3d_interpolation"><code class="docutils literal notranslate"><span class="pre">update_point_value_3d_interpolation()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/visualization.html#tensormesh.visualization.draw_point_value.draw_point_value"><code class="docutils literal notranslate"><span class="pre">draw_point_value()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/visualization.html#tensormesh.visualization.draw_point_value.update_point_value"><code class="docutils literal notranslate"><span class="pre">update_point_value()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/visualization.html#tensormesh.visualization.stream_plotter.StreamPlotter"><code class="docutils literal notranslate"><span class="pre">StreamPlotter</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/visualization.html#tensormesh.visualization.stream_plotter.StreamPlotter.__init__"><code class="docutils literal notranslate"><span class="pre">StreamPlotter.__init__()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/visualization.html#tensormesh.visualization.stream_plotter.StreamPlotter.grab_frame"><code class="docutils literal notranslate"><span class="pre">StreamPlotter.grab_frame()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/visualization.html#tensormesh.visualization.stream_plotter.StreamPlotter.update"><code class="docutils literal notranslate"><span class="pre">StreamPlotter.update()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/visualization.html#tensormesh.visualization.stream_plotter.StreamPlotter.draw_mesh_2d"><code class="docutils literal notranslate"><span class="pre">StreamPlotter.draw_mesh_2d()</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/visualization.html#tensormesh.visualization.stream_plotter.draw_mesh_2d_static"><code class="docutils literal notranslate"><span class="pre">draw_mesh_2d_static()</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/visualization.html#tensormesh.visualization.stream_plotter.draw_mesh_2d_stream"><code class="docutils literal notranslate"><span class="pre">draw_mesh_2d_stream()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../api_reference/profile.html">Profile</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../api_reference/profile.html#cpuprofiler">CPUProfiler</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/profile.html#tensormesh.profile.CPUProfiler"><code class="docutils literal notranslate"><span class="pre">CPUProfiler</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/profile.html#tensormesh.profile.CPUProfiler.pid"><code class="docutils literal notranslate"><span class="pre">CPUProfiler.pid</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/profile.html#tensormesh.profile.CPUProfiler.results"><code class="docutils literal notranslate"><span class="pre">CPUProfiler.results</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/profile.html#tensormesh.profile.CPUProfiler.times"><code class="docutils literal notranslate"><span class="pre">CPUProfiler.times</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/profile.html#tensormesh.profile.CPUProfiler.scopes"><code class="docutils literal notranslate"><span class="pre">CPUProfiler.scopes</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/profile.html#tensormesh.profile.CPUProfiler.__init__"><code class="docutils literal notranslate"><span class="pre">CPUProfiler.__init__()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/profile.html#tensormesh.profile.CPUProfiler.max"><code class="docutils literal notranslate"><span class="pre">CPUProfiler.max()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/profile.html#tensormesh.profile.CPUProfiler.min"><code class="docutils literal notranslate"><span class="pre">CPUProfiler.min()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/profile.html#tensormesh.profile.CPUProfiler.mean"><code class="docutils literal notranslate"><span class="pre">CPUProfiler.mean()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/profile.html#tensormesh.profile.CPUProfiler.std"><code class="docutils literal notranslate"><span class="pre">CPUProfiler.std()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/profile.html#tensormesh.profile.CPUProfiler.plot"><code class="docutils literal notranslate"><span class="pre">CPUProfiler.plot()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/profile.html#tensormesh.profile.CPUProfiler.scope"><code class="docutils literal notranslate"><span class="pre">CPUProfiler.scope()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../api_reference/profile.html#cudaprofiler">CUDAProfiler</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/profile.html#tensormesh.profile.CUDAProfiler"><code class="docutils literal notranslate"><span class="pre">CUDAProfiler</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/profile.html#tensormesh.profile.CUDAProfiler.__init__"><code class="docutils literal notranslate"><span class="pre">CUDAProfiler.__init__()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/profile.html#tensormesh.profile.CUDAProfiler.max"><code class="docutils literal notranslate"><span class="pre">CUDAProfiler.max()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/profile.html#tensormesh.profile.CUDAProfiler.min"><code class="docutils literal notranslate"><span class="pre">CUDAProfiler.min()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/profile.html#tensormesh.profile.CUDAProfiler.mean"><code class="docutils literal notranslate"><span class="pre">CUDAProfiler.mean()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/profile.html#tensormesh.profile.CUDAProfiler.std"><code class="docutils literal notranslate"><span class="pre">CUDAProfiler.std()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/profile.html#tensormesh.profile.CUDAProfiler.plot"><code class="docutils literal notranslate"><span class="pre">CUDAProfiler.plot()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/profile.html#tensormesh.profile.CUDAProfiler.scope"><code class="docutils literal notranslate"><span class="pre">CUDAProfiler.scope()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../api_reference/profile.html#timeprofiler">TimeProfiler</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../api_reference/profile.html#tensormesh.profile.TimeProfiler"><code class="docutils literal notranslate"><span class="pre">TimeProfiler</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/profile.html#tensormesh.profile.TimeProfiler.time"><code class="docutils literal notranslate"><span class="pre">TimeProfiler.time</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/profile.html#tensormesh.profile.TimeProfiler.start"><code class="docutils literal notranslate"><span class="pre">TimeProfiler.start</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/profile.html#tensormesh.profile.TimeProfiler.scopes"><code class="docutils literal notranslate"><span class="pre">TimeProfiler.scopes</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/profile.html#tensormesh.profile.TimeProfiler.only_cpu"><code class="docutils literal notranslate"><span class="pre">TimeProfiler.only_cpu</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/profile.html#tensormesh.profile.TimeProfiler.__init__"><code class="docutils literal notranslate"><span class="pre">TimeProfiler.__init__()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/profile.html#tensormesh.profile.TimeProfiler.scope"><code class="docutils literal notranslate"><span class="pre">TimeProfiler.scope()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../api_reference/profile.html#tensormesh.profile.TimeProfiler.plot"><code class="docutils literal notranslate"><span class="pre">TimeProfiler.plot()</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">tensormesh</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../index.html">Module code</a></li>
      <li class="breadcrumb-item active">tensormesh.element.polynomial</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for tensormesh.element.polynomial</h1><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">numpy</span> <span class="kn">import</span> <span class="n">where</span>
<span class="kn">from</span> <span class="nn">sympy</span> <span class="kn">import</span> <span class="n">N</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">lru_cache</span><span class="p">,</span> <span class="n">reduce</span>
<span class="kn">import</span> <span class="nn">math</span> 
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">re</span> 
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">List</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Type</span><span class="p">,</span> <span class="n">Sequence</span><span class="p">,</span> <span class="n">Union</span>



<div class="viewcode-block" id="Polynomial">
<a class="viewcode-back" href="../../../api_reference/element.html#tensormesh.element.polynomial.Polynomial">[docs]</a>
<span class="k">class</span> <span class="nc">Polynomial</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    </span>
<span class="sd">    A polynomial class representing multivariate polynomials of the form:</span>

<span class="sd">    .. math::</span>

<span class="sd">        p(x_1,\ldots,x_n) = \sum_{i=1}^m c_i \prod_{j=1}^n x_j^{e_{ij}}</span>

<span class="sd">    where:</span>
<span class="sd">    </span>
<span class="sd">    - :math:`n` is the number of variables (n_vars)</span>
<span class="sd">    - :math:`m` is the number of terms (n_terms) </span>
<span class="sd">    - :math:`c_i` are the coefficients (coef)</span>
<span class="sd">    - :math:`e_{ij}` are the exponents (exp)</span>
<span class="sd">    - :math:`x_j` are the variables</span>

<span class="sd">    For example, the polynomial :math:`x^2y + 2xy^2 + 3` has:</span>

<span class="sd">    - n_vars = 2 (x,y)</span>
<span class="sd">    - n_terms = 3</span>
<span class="sd">    - coef = [1, 2, 3]</span>
<span class="sd">    - exp = [[2,1,0], [1,2,0]]</span>
<span class="sd">    </span>
<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    .. code-block:: python</span>

<span class="sd">        # Create polynomial with exponents and coefficients</span>
<span class="sd">        exp = torch.tensor([[1, 2, 3], [2, 1, 0]]) # [n_vars(2), n_terms(3)]</span>
<span class="sd">        coef = torch.tensor([1, 1, 1])             # [n_terms(3)]</span>
<span class="sd">        poly = Polynomial(exp, coef)</span>
<span class="sd">        </span>
<span class="sd">        # Print polynomial</span>
<span class="sd">        print(poly)  # xy^2 + x^2y + x^3</span>
<span class="sd">        </span>
<span class="sd">        # Evaluate polynomial at point x</span>
<span class="sd">        x = torch.tensor([2, 3]) # [n_vars]</span>
<span class="sd">        print(poly(x))  # 2*3^2 + 2^2*3 + 2^3 = 38</span>
<span class="sd">        </span>
<span class="sd">        # Take derivatives</span>
<span class="sd">        print(poly.deriv(0))  # y^2 + 2xy + 3x^2</span>
<span class="sd">        print(poly.deriv(1))  # 2xy + x^2</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">_coef</span><span class="p">:</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> 
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Coefficients tensor of shape :math:`[N_t]` where:</span>
<span class="sd">    </span>
<span class="sd">    * :math:`N_t` = number of terms in polynomial</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">_exp</span><span class="p">:</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>  
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Exponents tensor of shape :math:`[N_v, N_t]` where:</span>
<span class="sd">    </span>
<span class="sd">    * :math:`N_v` = number of variables</span>
<span class="sd">    * :math:`N_t` = number of terms in polynomial</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">n_vars</span><span class="p">:</span><span class="nb">int</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Number of variables in polynomial</span>
<span class="sd">    :no-index:</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">n_terms</span><span class="p">:</span><span class="nb">int</span> 
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Number of terms in polynomial</span>
<span class="sd">    :no-index:</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="Polynomial.__init__">
<a class="viewcode-back" href="../../../api_reference/element.html#tensormesh.element.polynomial.Polynomial.__init__">[docs]</a>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> 
                 <span class="n">exp</span><span class="p">:</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> 
                 <span class="n">coef</span><span class="p">:</span><span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize a polynomial with exponents and coefficients.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        exp : torch.Tensor</span>
<span class="sd">            Exponents tensor of shape :math:`[N_v, N_t]` where:</span>
<span class="sd">            </span>
<span class="sd">            * :math:`N_v` = number of variables</span>
<span class="sd">            * :math:`N_t` = number of terms</span>
<span class="sd">        coef : Optional[torch.Tensor], optional</span>
<span class="sd">            Coefficients tensor of shape :math:`[N_t]`, by default None.</span>
<span class="sd">            If None, coefficients will be initialized as ones.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        .. code-block:: python</span>

<span class="sd">            # Create polynomial x^2y + 2xy^2 + 3</span>
<span class="sd">            exp = torch.tensor([[2,1,0], [1,2,0]])  # [2 vars, 3 terms]</span>
<span class="sd">            coef = torch.tensor([1,2,3])            # [3 terms]</span>
<span class="sd">            poly = Polynomial(exp, coef)</span>

<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="k">assert</span> <span class="n">exp</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">2</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;exp should be of shape [n_vars, n_terms], but got exp of shape </span><span class="si">{</span><span class="n">exp</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="k">if</span> <span class="n">coef</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">coef</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">exp</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">dtype</span><span class="o">=</span><span class="n">exp</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">exp</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">assert</span> <span class="p">(</span><span class="n">coef</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> 
                <span class="n">coef</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">exp</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="p">(</span><span class="sa">f</span><span class="s2">&quot;coef should be of shape [n_terms], exp should be of shape [n_vars, n_terms], &quot;</span>
                                               <span class="sa">f</span><span class="s2">&quot;but got coef of shape </span><span class="si">{</span><span class="n">coef</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">, and exp of shape </span><span class="si">{</span><span class="n">exp</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">assert</span> <span class="n">exp</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">coef</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;exp and coef should have the same dtype, but got </span><span class="si">{</span><span class="n">exp</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s2"> and </span><span class="si">{</span><span class="n">coef</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="k">assert</span> <span class="n">exp</span><span class="o">.</span><span class="n">device</span> <span class="o">==</span> <span class="n">coef</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;exp and coef should have the same device, but got </span><span class="si">{</span><span class="n">exp</span><span class="o">.</span><span class="n">device</span><span class="si">}</span><span class="s2"> and </span><span class="si">{</span><span class="n">coef</span><span class="o">.</span><span class="n">device</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;_coef&#39;</span><span class="p">,</span> <span class="n">coef</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;_exp&#39;</span><span class="p">,</span> <span class="n">exp</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_vars</span>  <span class="o">=</span> <span class="n">exp</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_terms</span> <span class="o">=</span> <span class="n">exp</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span></div>


    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get number of terms in polynomial.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        int</span>
<span class="sd">            Number of terms in polynomial</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_terms</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">:</span><span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span><span class="nb">slice</span><span class="p">,</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span>
                    <span class="p">)</span><span class="o">-&gt;</span><span class="n">Union</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>
                        <span class="s1">&#39;Polynomial&#39;</span><span class="p">,</span>
                        <span class="s1">&#39;Polynomials&#39;</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get subset of polynomial terms.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        index : Union[int, slice, torch.Tensor]</span>
<span class="sd">            Index to select terms:</span>
<span class="sd">            </span>
<span class="sd">            * int: single term</span>
<span class="sd">            * slice: range of terms</span>
<span class="sd">            * tensor: boolean or integer indices</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Union[Tuple[torch.Tensor, torch.Tensor], Polynomial, Polynomials]</span>
<span class="sd">            * For single term: (coefficient, exponents) tuple</span>
<span class="sd">            * For multiple terms: new Polynomial</span>
<span class="sd">            * For multiple polynomials: new Polynomials</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">_coef</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_coef</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
        <span class="n">_exp</span>  <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_exp</span><span class="p">[:,</span> <span class="n">index</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">_coef</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">_coef</span><span class="p">,</span> <span class="n">_exp</span>
        <span class="k">elif</span> <span class="n">_coef</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">Polynomial</span><span class="p">(</span><span class="n">_exp</span><span class="p">,</span> <span class="n">_coef</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">_coef</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">Polynomials</span><span class="p">(</span><span class="n">_exp</span><span class="p">,</span> <span class="n">_coef</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Invalid input shape </span><span class="si">{</span><span class="n">index</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__str__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">max_show_col</span><span class="p">:</span><span class="nb">int</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
        <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_vars</span> <span class="o">&lt;=</span> <span class="mi">26</span><span class="p">,</span> <span class="s2">&quot;The number of variables should be less than 26&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_vars</span> <span class="o">&lt;=</span> <span class="mi">26</span><span class="p">:</span>
            <span class="n">VAR_NAME</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nb">list</span><span class="p">(</span><span class="s2">&quot;xyzabcdefghijklmnopqrstuvw&quot;</span><span class="p">)[</span><span class="n">x</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">VAR_NAME</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;(x</span><span class="si">{</span><span class="n">x</span><span class="si">}</span><span class="s2">)&quot;</span>
        <span class="n">string</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">c</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_coef</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">c</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">c</span> <span class="o">=</span> <span class="n">c</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
                <span class="n">_vars</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="n">e</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_exp</span><span class="p">[:,</span><span class="n">i</span><span class="p">]):</span>
                    <span class="k">if</span> <span class="n">e</span> <span class="o">==</span> <span class="mf">0.</span><span class="p">:</span>
                        <span class="n">_vars</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
                    <span class="k">elif</span> <span class="n">e</span> <span class="o">==</span> <span class="mf">1.</span><span class="p">:</span>
                        <span class="n">_vars</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">VAR_NAME</span><span class="p">(</span><span class="n">j</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">_vars</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">VAR_NAME</span><span class="p">(</span><span class="n">j</span><span class="p">)</span><span class="si">}</span><span class="s2">^</span><span class="si">{</span><span class="n">e</span><span class="si">:</span><span class="s2">.2g</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">_vars</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">c</span> <span class="o">==</span> <span class="mf">1.</span><span class="p">:</span> 
                    <span class="k">if</span> <span class="nb">all</span><span class="p">([</span><span class="n">x</span> <span class="o">==</span> <span class="s2">&quot;&quot;</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">_vars</span><span class="p">]):</span>
                        <span class="n">string</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;1&quot;</span><span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">string</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">_vars</span><span class="p">))</span>
                <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">_vars</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">c</span> <span class="o">==</span> <span class="o">-</span><span class="mf">1.</span><span class="p">:</span>
                    <span class="k">if</span> <span class="nb">all</span><span class="p">([</span><span class="n">x</span> <span class="o">==</span> <span class="s2">&quot;&quot;</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">_vars</span><span class="p">]):</span>
                        <span class="n">string</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot;-1&quot;</span><span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">string</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">&#39;-&#39;</span> <span class="o">+</span> <span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">_vars</span><span class="p">))</span>
                <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">_vars</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="nb">all</span><span class="p">([</span><span class="n">x</span> <span class="o">==</span> <span class="s2">&quot;&quot;</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">_vars</span><span class="p">]):</span>
                    <span class="n">string</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">c</span><span class="si">:</span><span class="s2">.2g</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">string</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">c</span><span class="si">:</span><span class="s2">.2g</span><span class="si">}{</span><span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">_vars</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">max_show_col</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">string</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">max_show_col</span> <span class="o">*</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">string</span> <span class="o">=</span> <span class="n">string</span><span class="p">[:</span><span class="n">max_show_col</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="s2">&quot;...&quot;</span><span class="p">]</span> <span class="o">+</span> <span class="n">string</span><span class="p">[</span><span class="o">-</span><span class="n">max_show_col</span><span class="p">:]</span>
              

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">string</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="s2">&quot;0&quot;</span>
        <span class="n">result</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">term</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">string</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">result</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">term</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">term</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;-&quot;</span><span class="p">):</span>
                    <span class="n">result</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot; &quot;</span> <span class="o">+</span> <span class="n">term</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">result</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s2">&quot; + &quot;</span> <span class="o">+</span> <span class="n">term</span><span class="p">)</span>
        <span class="k">return</span> <span class="s2">&quot;&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>

<div class="viewcode-block" id="Polynomial.forward">
<a class="viewcode-back" href="../../../api_reference/element.html#tensormesh.element.polynomial.Polynomial.forward">[docs]</a>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span><span class="o">-&gt;</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Evaluate the polynomial at given points.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        .. code-block:: python</span>

<span class="sd">            # Create a polynomial p(x,y) = 2x + 3y^2</span>
<span class="sd">            coef = torch.tensor([2.0, 3.0])</span>
<span class="sd">            exp = torch.tensor([[1.0, 0.0], [0.0, 2.0]])</span>
<span class="sd">            poly = Polynomial(coef, exp)</span>
<span class="sd">            </span>
<span class="sd">            # Evaluate at single point</span>
<span class="sd">            x = torch.tensor([1.0, 2.0])  # point (x=1, y=2)</span>
<span class="sd">            poly(x)  # 2*1 + 3*2^2 = 14.0</span>
<span class="sd">            # tensor(14.)</span>
<span class="sd">            </span>
<span class="sd">            # Evaluate at multiple points</span>
<span class="sd">            x = torch.tensor([[1.0, 2.0], [2.0, 1.0]])  # points (1,2) and (2,1)</span>
<span class="sd">            poly(x)  # [2*1 + 3*2^2, 2*2 + 3*1^2] = [14.0, 7.0]</span>
<span class="sd">            # tensor([14., 7.])</span>


<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        x : torch.Tensor [n_batch, n_vars] or [n_vars]</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        torch.Tensor [n_batch] or torch.Float</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="n">x</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;x and polynomial should have the same dtype, but got </span><span class="si">{</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s2"> and </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="k">assert</span> <span class="n">x</span><span class="o">.</span><span class="n">device</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;x and polynomial should have the same device, but got </span><span class="si">{</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="si">}</span><span class="s2"> and </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="k">assert</span> <span class="n">x</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">or</span> <span class="n">x</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">2</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;x should be of shape [n_batch, n_vars] or [n_vars], but got x of shape </span><span class="si">{</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="k">assert</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_vars</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;x should have the same number of variables as the polynomial, but got </span><span class="si">{</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2"> and </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">n_vars</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_exp_terms</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="c1"># [n_batch, n_terms] or [n_terms]</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">_coef</span>
        
        <span class="k">return</span> <span class="n">x</span></div>


<div class="viewcode-block" id="Polynomial.get_exp_terms">
<a class="viewcode-back" href="../../../api_reference/element.html#tensormesh.element.polynomial.Polynomial.get_exp_terms">[docs]</a>
    <span class="k">def</span> <span class="nf">get_exp_terms</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span><span class="o">-&gt;</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Compute exponential terms for polynomial evaluation.</span>

<span class="sd">        For a polynomial with terms :math:`c_i x_1^{e_{i1}} x_2^{e_{i2}} \cdots x_n^{e_{in}}`,</span>
<span class="sd">        computes the exponential terms :math:`x_1^{e_{i1}} x_2^{e_{i2}} \cdots x_n^{e_{in}}` </span>
<span class="sd">        for each term i.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        .. code-block:: python</span>

<span class="sd">            # Create polynomial p(x,y) = 2x^2y + 3xy^2</span>
<span class="sd">            exp = torch.tensor([[2,1], [1,2]])  # exponents for each term</span>
<span class="sd">            coef = torch.tensor([2.0, 3.0])     # coefficients</span>
<span class="sd">            poly = Polynomial(coef, exp)</span>

<span class="sd">            # Single point evaluation</span>
<span class="sd">            x = torch.tensor([2.0, 3.0])  # point (x=2, y=3)</span>
<span class="sd">            terms = poly.get_exp_terms(x)  # [2^2 * 3^1, 2^1 * 3^2]</span>
<span class="sd">            # tensor([12., 54.])</span>

<span class="sd">            # Multiple point evaluation  </span>
<span class="sd">            x = torch.tensor([[2.0, 3.0], [1.0, 2.0]])  # points (2,3) and (1,2)</span>
<span class="sd">            terms = poly.get_exp_terms(x)  # [[2^2 * 3^1, 2^1 * 3^2], [1^2 * 2^1, 1^1 * 2^2]]</span>
<span class="sd">            # tensor([[12., 54.],</span>
<span class="sd">            #         [ 2.,  4.]])</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        x : torch.Tensor</span>
<span class="sd">            Input points tensor of shape:</span>
<span class="sd">            * [n_vars] for single point</span>
<span class="sd">            * [n_batch, n_vars] for multiple points</span>
<span class="sd">            where:</span>
<span class="sd">            * n_vars = number of variables</span>
<span class="sd">            * n_batch = number of points</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        torch.Tensor</span>
<span class="sd">            Exponential terms tensor of shape:</span>
<span class="sd">            * [n_terms] for single point input</span>
<span class="sd">            * [n_batch, n_terms] for multiple point input</span>
<span class="sd">            where:</span>
<span class="sd">            * n_terms = number of polynomial terms</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="n">x</span><span class="o">.</span><span class="n">dtype</span>  <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;x and self should have the same dtype, but got </span><span class="si">{</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s2"> and </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="k">assert</span> <span class="n">x</span><span class="o">.</span><span class="n">device</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;x and self should have the same device, but got </span><span class="si">{</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="si">}</span><span class="s2"> and </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">x</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">_exp</span><span class="p">)</span> <span class="c1"># [n_vars, n_terms]</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>    <span class="c1"># [n_terms]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">assert</span> <span class="n">x</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">2</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;x should be of shape [n_batch, n_vars], but got x of shape </span><span class="si">{</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="c1"># breakpoint()</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">x</span><span class="p">[:,</span> <span class="p">:,</span> <span class="kc">None</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">_exp</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:])</span> <span class="c1"># [n_batch, n_vars, n_terms]</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>    <span class="c1"># [n_batch, n_terms]</span>
        <span class="k">return</span> <span class="n">x</span></div>

        
<div class="viewcode-block" id="Polynomial.deriv">
<a class="viewcode-back" href="../../../api_reference/element.html#tensormesh.element.polynomial.Polynomial.deriv">[docs]</a>
    <span class="k">def</span> <span class="nf">deriv</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">var_ind</span><span class="p">:</span><span class="nb">int</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">-&gt;</span><span class="s1">&#39;Polynomial&#39;</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the derivative of the polynomial with respect to a variable.</span>

<span class="sd">        For a polynomial :math:`p(x,y,z) = ax^ny^mz^k`, the derivative with respect to x is:</span>
<span class="sd">        :math:`\frac{\partial p}{\partial x} = nax^{n-1}y^mz^k` if n&gt;0, or 0 if n=0</span>
<span class="sd">        </span>
<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        .. code-block:: python</span>

<span class="sd">            # Create polynomial p(x,y) = x^2y + 2xy^2 + 3</span>
<span class="sd">            exp = torch.tensor([[2, 1, 0], [1, 2, 0]]) # [n_vars(2), n_terms(3)]</span>
<span class="sd">            coef = torch.tensor([1, 2, 3])             # [n_terms(3)]</span>
<span class="sd">            poly = Polynomial(exp, coef)</span>

<span class="sd">            # Take derivative with respect to x</span>
<span class="sd">            dx = poly.deriv(0)  # 2xy + 2y^2</span>
<span class="sd">            print(dx)</span>

<span class="sd">            # Take derivative with respect to y  </span>
<span class="sd">            dy = poly.deriv(1)  # x^2 + 4xy</span>
<span class="sd">            print(dy)</span>

<span class="sd">            # Evaluate derivatives at point (2,3)</span>
<span class="sd">            x = torch.tensor([2.0, 3.0])</span>
<span class="sd">            print(dx(x))  # 2*2*3 + 2*3^2 = 30</span>
<span class="sd">            print(dy(x))  # 2^2 + 4*2*3 = 28</span>


<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        var_ind: int </span>
<span class="sd">                the index of the variable to be differentiated</span>
<span class="sd">    </span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        deriv_poly: Polynomial</span>
<span class="sd">                    the derivative of the polynomial</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="n">var_ind</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_vars</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;var_ind should be less than </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">n_vars</span><span class="si">}</span><span class="s2">, but got </span><span class="si">{</span><span class="n">var_ind</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="n">coef</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_coef</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="n">exp</span>  <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_exp</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
        <span class="n">where_constant</span> <span class="o">=</span> <span class="n">exp</span><span class="p">[</span><span class="n">var_ind</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span>
        <span class="n">exp</span><span class="p">[</span><span class="n">var_ind</span><span class="p">]</span> <span class="o">=</span> <span class="n">exp</span><span class="p">[</span><span class="n">var_ind</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span>
        <span class="n">exp</span><span class="p">[</span><span class="n">var_ind</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp_min</span><span class="p">(</span><span class="n">exp</span><span class="p">[</span><span class="n">var_ind</span><span class="p">],</span> <span class="mf">0.0</span><span class="p">)</span>
        <span class="n">mask</span>         <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">coef</span><span class="p">)</span>
        <span class="n">mask</span><span class="p">[</span><span class="n">where_constant</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">coef</span>     <span class="o">=</span> <span class="n">coef</span> <span class="o">*</span> <span class="p">(</span><span class="n">exp</span><span class="p">[</span><span class="n">var_ind</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">mask</span>        
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="p">(</span><span class="n">exp</span><span class="p">,</span> <span class="n">coef</span><span class="p">)</span></div>

    
<div class="viewcode-block" id="Polynomial.grad">
<a class="viewcode-back" href="../../../api_reference/element.html#tensormesh.element.polynomial.Polynomial.grad">[docs]</a>
    <span class="k">def</span> <span class="nf">grad</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="o">-&gt;</span><span class="s1">&#39;Polynomials&#39;</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the gradient of the polynomial.</span>

<span class="sd">        For a polynomial :math:`p(x_1,\ldots,x_n)`, returns a vector of partial derivatives:</span>
<span class="sd">        :math:`\nabla p = [\frac{\partial p}{\partial x_1}, \ldots, \frac{\partial p}{\partial x_n}]`</span>

<span class="sd">        For example, given :math:`p(x,y) = ax^ny^m`, the gradient is:</span>
<span class="sd">        :math:`\nabla p = [nax^{n-1}y^m, max^ny^{m-1}]`</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        .. code-block:: python</span>

<span class="sd">            # Create polynomial p(x,y) = x^2y + 2xy^2 + 3</span>
<span class="sd">            exp = torch.tensor([[2, 1, 0], [1, 2, 0]]) # [n_vars(2), n_terms(3)]</span>
<span class="sd">            coef = torch.tensor([1, 2, 3])             # [n_terms(3)]</span>
<span class="sd">            poly = Polynomial(exp, coef)</span>

<span class="sd">            # Take gradient</span>
<span class="sd">            grad = poly.grad()  # [2xy + 2y^2, x^2 + 4xy]</span>
<span class="sd">            print(grad)</span>

<span class="sd">            # Evaluate gradient at point (2,3)</span>
<span class="sd">            x = torch.tensor([2.0, 3.0])</span>
<span class="sd">            print(grad(x))  # [30, 28]</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        None</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        grad_poly: Polynomials</span>
<span class="sd">                    the gradient of the polynomial</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># TODO: Could be more efficient</span>
        <span class="k">return</span> <span class="n">Polynomials</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">deriv</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_vars</span><span class="p">)])</span></div>


<div class="viewcode-block" id="Polynomial.reset_coef">
<a class="viewcode-back" href="../../../api_reference/element.html#tensormesh.element.polynomial.Polynomial.reset_coef">[docs]</a>
    <span class="k">def</span> <span class="nf">reset_coef</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">coef</span><span class="p">:</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Reset the coefficients of the polynomial while keeping the exponents unchanged.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        coef: torch.Tensor</span>
<span class="sd">            The new coefficients to set. Must match the shape, device and dtype of the existing coefficients.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        self: Polynomial</span>
<span class="sd">            Returns self for method chaining.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">assert</span> <span class="n">coef</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">_coef</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;reset coef error: expected </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_coef</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2"> but got </span><span class="si">{</span><span class="n">coef</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="k">assert</span> <span class="n">coef</span><span class="o">.</span><span class="n">device</span><span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;reset coef error: expected </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="si">}</span><span class="s2"> but got </span><span class="si">{</span><span class="n">coef</span><span class="o">.</span><span class="n">device</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="k">assert</span> <span class="n">coef</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;reset coef error: expected </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s2"> but got </span><span class="si">{</span><span class="n">coef</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s2">&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_coef</span> <span class="o">=</span> <span class="n">coef</span>

        <span class="k">return</span> <span class="bp">self</span></div>


<div class="viewcode-block" id="Polynomial.repeat">
<a class="viewcode-back" href="../../../api_reference/element.html#tensormesh.element.polynomial.Polynomial.repeat">[docs]</a>
    <span class="k">def</span> <span class="nf">repeat</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">)</span><span class="o">-&gt;</span><span class="s1">&#39;Polynomials&#39;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Repeat the polynomial along specified dimensions.</span>

<span class="sd">        Creates a new Polynomials object by repeating the current polynomial&#39;s coefficients and </span>
<span class="sd">        exponents according to the provided repeat dimensions. This is similar to torch.repeat().</span>

<span class="sd">        For example:</span>
<span class="sd">        </span>
<span class="sd">        - repeat(3) creates 3 copies along a new first dimension</span>
<span class="sd">        - repeat(2,3) creates a 2x3 grid of copies in new dimensions</span>

<span class="sd">        The coefficients and exponents are repeated while preserving the polynomial structure,</span>
<span class="sd">        effectively creating multiple independent copies of the same polynomial.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        .. code-block:: python</span>

<span class="sd">            # Create a polynomial</span>
<span class="sd">            exp = torch.tensor([[2, 1], [1, 0]])  # x^2y + x</span>
<span class="sd">            coef = torch.tensor([1.0, 1.0])</span>
<span class="sd">            poly = Polynomial(exp, coef)</span>

<span class="sd">            # Repeat 3 times along new first dimension</span>
<span class="sd">            polys1 = poly.repeat(3)  # Shape: [3, n_vars, n_terms]</span>

<span class="sd">            # Create 2x3 grid of copies</span>
<span class="sd">            polys2 = poly.repeat(2, 3)  # Shape: [2, 3, n_vars, n_terms]</span>

<span class="sd">            # Evaluate repeated polynomials</span>
<span class="sd">            x = torch.randn(2, 3, 2)  # [2, 3, n_vars]</span>
<span class="sd">            y = polys2(x)  # [2, 3] outputs</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        *args : int</span>
<span class="sd">            The number of repetitions for each new dimension. Similar to torch.repeat() arguments.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Polynomials</span>
<span class="sd">            A new Polynomials object with the repeated structure. The shape will be [*args, ...original_shape].</span>
<span class="sd">        &quot;&quot;&quot;</span>
        
        <span class="n">exps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_exp</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">args</span><span class="p">),</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">coef</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_coef</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">args</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">exps</span> <span class="o">=</span> <span class="n">exps</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_vars</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_terms</span><span class="p">)</span>
        <span class="n">coef</span> <span class="o">=</span> <span class="n">coef</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_terms</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">Polynomials</span><span class="p">(</span><span class="n">exps</span><span class="p">,</span> <span class="n">coef</span><span class="p">)</span></div>

       
<div class="viewcode-block" id="Polynomial.lin_exp">
<a class="viewcode-back" href="../../../api_reference/element.html#tensormesh.element.polynomial.Polynomial.lin_exp">[docs]</a>
    <span class="nd">@classmethod</span> 
    <span class="k">def</span> <span class="nf">lin_exp</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> 
                <span class="n">n_vars</span><span class="p">:</span><span class="nb">int</span><span class="p">,</span> 
                <span class="n">dtype</span><span class="p">:</span><span class="n">torch</span><span class="o">.</span><span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> 
                <span class="n">device</span><span class="p">:</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
                <span class="p">)</span><span class="o">-&gt;</span><span class="s1">&#39;Polynomial&#39;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Creates a linear polynomial with n_vars variables.</span>
<span class="sd">        Creates a polynomial with ``n_vars+1`` terms:</span>

<span class="sd">        * A constant term (all exponents 0)</span>
<span class="sd">        * Linear terms for each variable (exponent 1 for that variable, 0 for others)</span>

<span class="sd">        For example, with n_vars=2, creates polynomial with terms:</span>
<span class="sd">        :math:`1, x, y`</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        .. code-block:: python</span>

<span class="sd">            # Create linear polynomial with 2 variables (1 + x + y)</span>
<span class="sd">            poly = Polynomial.lin_exp(2)</span>
<span class="sd">            print(poly)  # 1 + x + y</span>

<span class="sd">            # Create linear polynomial with 3 variables (1 + x + y + z)</span>
<span class="sd">            poly = Polynomial.lin_exp(3)</span>
<span class="sd">            print(poly)  # 1 + x + y + z</span>

<span class="sd">            # Specify dtype and device</span>
<span class="sd">            poly = Polynomial.lin_exp(2, dtype=torch.float64, device=torch.device(&#39;cuda&#39;))</span>
<span class="sd">            print(poly.dtype)  # torch.float64</span>
<span class="sd">            print(poly.device)  # cuda:0</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        n_vars: int </span>
<span class="sd">            number of vairables</span>
<span class="sd">        dtype: torch.dtype</span>
<span class="sd">            the data type of the polynomial</span>
<span class="sd">        device: torch.device</span>
<span class="sd">            the device of the polynomial</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        polynomial: Polynomial n_vars=n_vars n_terms=n_vars+1</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">exp</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_vars</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">n_vars</span><span class="p">)</span>
        <span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># [n_vars, n_vars+1]</span>
        <span class="n">exp</span> <span class="o">=</span> <span class="n">exp</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">Polynomial</span><span class="p">(</span><span class="n">exp</span><span class="p">)</span></div>

                
<div class="viewcode-block" id="Polynomial.poly_exp">
<a class="viewcode-back" href="../../../api_reference/element.html#tensormesh.element.polynomial.Polynomial.poly_exp">[docs]</a>
    <span class="nd">@classmethod</span> 
    <span class="k">def</span> <span class="nf">poly_exp</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> 
                 <span class="n">n_vars</span><span class="p">:</span><span class="nb">int</span><span class="p">,</span> 
                 <span class="n">dim</span><span class="p">:</span><span class="nb">int</span><span class="p">,</span>
                 <span class="n">dtype</span><span class="p">:</span><span class="n">torch</span><span class="o">.</span><span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span>
                 <span class="n">device</span><span class="p">:</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
                 <span class="p">)</span><span class="o">-&gt;</span><span class="s1">&#39;Polynomial&#39;</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Creates a polynomial with terms up to a maximum total degree.</span>

<span class="sd">        For n_vars variables and maximum degree dim, includes all terms where</span>
<span class="sd">        the sum of exponents is less than or equal to dim, sorted by total degree.</span>

<span class="sd">        For example, with n_vars=2, dim=2, creates polynomial with terms:</span>
<span class="sd">        :math:`1, x, y, x^2, xy, y^2`</span>

<span class="sd">        For n_vars=1, creates polynomial with terms up to power dim:</span>
<span class="sd">        :math:`1, x, x^2, \ldots, x^{dim}`</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        .. code-block:: python</span>

<span class="sd">            # Create polynomial with terms up to degree 2 in 2 variables</span>
<span class="sd">            poly = Polynomial.poly_exp(2, 2)</span>
<span class="sd">            print(poly)  # 1 + x + y + x^2 + xy + y^2</span>

<span class="sd">            # Create polynomial with terms up to degree 3 in 1 variable </span>
<span class="sd">            poly = Polynomial.poly_exp(1, 3)</span>
<span class="sd">            print(poly)  # 1 + x + x^2 + x^3</span>

<span class="sd">            # Create polynomial with terms up to degree 2 in 3 variables</span>
<span class="sd">            poly = Polynomial.poly_exp(3, 2)</span>
<span class="sd">            print(poly)  # 1 + x + y + z + x^2 + xy + xz + y^2 + yz + z^2</span>

<span class="sd">            # Specify dtype and device</span>
<span class="sd">            poly = Polynomial.poly_exp(2, 2, dtype=torch.float64, device=torch.device(&#39;cuda&#39;))</span>
<span class="sd">            print(poly.dtype)  # torch.float64</span>
<span class="sd">            print(poly.device)  # cuda:0</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        n_vars: int </span>
<span class="sd">            number of vairables</span>
<span class="sd">        dim: int</span>
<span class="sd">            number of maximum dimension </span>
<span class="sd">        dtype: torch.dtype</span>
<span class="sd">            the data type of the polynomial</span>
<span class="sd">        device: torch.device</span>
<span class="sd">            the device of the polynomial</span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        polynomial: Polynomial n_vars=n_vars </span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">n_vars</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">exp</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">dim</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">axes</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="o">*</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">dim</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_vars</span><span class="p">)],</span> <span class="n">indexing</span><span class="o">=</span><span class="s1">&#39;xy&#39;</span><span class="p">)</span>
            <span class="n">axes</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">axes</span><span class="p">))</span>
            <span class="n">exp</span>  <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">axes</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
            <span class="n">exp</span>  <span class="o">=</span> <span class="n">exp</span><span class="p">[:,</span> <span class="n">exp</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">dim</span><span class="p">]</span>
            <span class="n">exp</span>  <span class="o">=</span> <span class="n">exp</span><span class="p">[:,</span> <span class="n">exp</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">argsort</span><span class="p">()]</span>

        <span class="n">exp</span> <span class="o">=</span> <span class="n">exp</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">Polynomial</span><span class="p">(</span><span class="n">exp</span><span class="p">)</span></div>


<div class="viewcode-block" id="Polynomial.tens_exp">
<a class="viewcode-back" href="../../../api_reference/element.html#tensormesh.element.polynomial.Polynomial.tens_exp">[docs]</a>
    <span class="nd">@classmethod</span> 
    <span class="k">def</span> <span class="nf">tens_exp</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> 
                 <span class="n">n_vars</span><span class="p">:</span><span class="nb">int</span><span class="p">,</span> 
                 <span class="n">dim</span><span class="p">:</span><span class="nb">int</span><span class="p">,</span>
                 <span class="n">dtype</span><span class="p">:</span><span class="n">torch</span><span class="o">.</span><span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span>  
                 <span class="n">device</span><span class="p">:</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
                 <span class="p">)</span><span class="o">-&gt;</span><span class="s1">&#39;Polynomial&#39;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Creates a tensor product polynomial with terms up to maximum degree in each variable.</span>

<span class="sd">        For n_vars variables and maximum degree dim, includes all terms where</span>
<span class="sd">        each exponent is less than or equal to dim, sorted by total degree.</span>

<span class="sd">        For example, with n_vars=2, dim=2, creates polynomial with terms:</span>
<span class="sd">        :math:`P(x,y) = a_0 + a_1x + a_2y + a_3x^2 + a_4xy + a_5y^2 + a_6x^2y + a_7xy^2 + a_8x^2y^2`</span>

<span class="sd">        For n_vars=1, dim=d, creates polynomial with terms up to power dim:</span>
<span class="sd">        :math:`P(x) = a_0 + a_1x + a_2x^2 + ... + a_dx^d`</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        .. code-block:: python</span>

<span class="sd">            # Create tensor product polynomial with 2 variables up to degree 2</span>
<span class="sd">            poly = Polynomial.tens_exp(2, 2)</span>
<span class="sd">            print(poly)  # 1 + x + y + x^2 + xy + y^2 + x^2y + xy^2 + x^2y^2</span>
<span class="sd">            </span>
<span class="sd">            # Create tensor product polynomial with 1 variable up to degree 3</span>
<span class="sd">            poly = Polynomial.tens_exp(1, 3)</span>
<span class="sd">            print(poly)  # 1 + x + x^2 + x^3</span>
<span class="sd">            </span>
<span class="sd">            # Specify dtype and device</span>
<span class="sd">            poly = Polynomial.tens_exp(2, 2, dtype=torch.float64, device=torch.device(&#39;cuda&#39;))</span>
<span class="sd">            print(poly.dtype)  # torch.float64</span>
<span class="sd">            print(poly.device)  # cuda:0</span>
<span class="sd">        </span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        n_vars: int </span>
<span class="sd">            number of vairables</span>
<span class="sd">        dim: int</span>
<span class="sd">            number of maximum dimension </span>
<span class="sd">        dtype: torch.dtype</span>
<span class="sd">            the data type of the polynomial</span>
<span class="sd">        device: torch.device</span>
<span class="sd">            the device of the polynomial</span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        polynomial: Polynomial n_vars=n_vars n_terms=(dim+1)**n_vars</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">n_vars</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">exp</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">dim</span><span class="o">+</span><span class="mi">1</span><span class="p">)[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:]</span> <span class="c1"># [1, dim+1]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">axes</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="o">*</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">dim</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_vars</span><span class="p">)],</span> <span class="n">indexing</span><span class="o">=</span><span class="s1">&#39;xy&#39;</span><span class="p">)</span> 
            <span class="n">axes</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">axes</span><span class="p">))</span>
            <span class="n">exp</span>  <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">axes</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span> <span class="c1"># [n_vars, (dim+1)**n_vars]</span>
            <span class="n">exp</span>  <span class="o">=</span> <span class="n">exp</span><span class="p">[:,</span> <span class="n">exp</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">argsort</span><span class="p">()]</span>

        <span class="n">exp</span> <span class="o">=</span> <span class="n">exp</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">Polynomial</span><span class="p">(</span><span class="n">exp</span><span class="p">)</span></div>


<div class="viewcode-block" id="Polynomial.pyr_exp">
<a class="viewcode-back" href="../../../api_reference/element.html#tensormesh.element.polynomial.Polynomial.pyr_exp">[docs]</a>
    <span class="nd">@classmethod</span> 
    <span class="k">def</span> <span class="nf">pyr_exp</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> 
                <span class="n">order</span><span class="p">:</span><span class="nb">int</span><span class="p">,</span>
                <span class="n">dtype</span><span class="p">:</span><span class="n">torch</span><span class="o">.</span><span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span>
                <span class="n">device</span><span class="p">:</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
                <span class="p">)</span><span class="o">-&gt;</span><span class="s1">&#39;Polynomial&#39;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Creates a pyramid polynomial with terms up to maximum total degree.</span>

<span class="sd">        For order n, includes all terms where x+z &lt; n+1 and y+z &lt; n+1, sorted by total degree.</span>

<span class="sd">        For example, with order=1, creates polynomial with terms:</span>
<span class="sd">        :math:`P(x,y,z) = a_0 + a_1x + a_2y + a_3z`</span>

<span class="sd">        With order=2, creates polynomial with terms:</span>
<span class="sd">        :math:`P(x,y,z) = a_0 + a_1x + a_2y + a_3z + a_4x^2 + a_5xy + a_6y^2 + a_7xz + a_8yz + a_9z^2`</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        .. code-block:: python</span>

<span class="sd">            # Create order 1 pyramid polynomial</span>
<span class="sd">            poly = Polynomial.pyr_exp(1)</span>
<span class="sd">            print(poly)  # 1 + x + y + z</span>
<span class="sd">            </span>
<span class="sd">            # Create order 2 pyramid polynomial with custom dtype and device</span>
<span class="sd">            poly = Polynomial.pyr_exp(2, dtype=torch.float64, device=torch.device(&#39;cuda&#39;))</span>
<span class="sd">            print(poly.dtype)  # torch.float64</span>
<span class="sd">            print(poly.device)  # cuda:0</span>
<span class="sd">            </span>
<span class="sd">            # Evaluate polynomial at point x</span>
<span class="sd">            x = torch.tensor([1.0, 2.0, 0.5], device=&#39;cuda&#39;, dtype=torch.float64)  # [x,y,z]</span>
<span class="sd">            print(poly(x))  # Evaluates polynomial at (1,2,0.5)</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        order : int</span>
<span class="sd">            Maximum polynomial order</span>
<span class="sd">        dtype : torch.dtype, optional</span>
<span class="sd">            Data type of polynomial coefficients</span>
<span class="sd">        device : torch.device, optional</span>
<span class="sd">            Device to store polynomial on</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        polynomial : Polynomial</span>
<span class="sd">            Pyramid polynomial with n_vars=3 and appropriate number of terms</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">axes</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">order</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> 
                              <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">order</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> 
                              <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">order</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> 
                              <span class="n">indexing</span><span class="o">=</span><span class="s1">&#39;xy&#39;</span><span class="p">)</span>
        <span class="n">axes</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">axes</span><span class="p">))</span>
        <span class="n">exp</span>  <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">axes</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="n">exp</span>  <span class="o">=</span> <span class="n">exp</span><span class="p">[:,</span> <span class="p">(</span><span class="n">exp</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">+</span><span class="n">exp</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">order</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">exp</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">+</span><span class="n">exp</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">order</span><span class="o">+</span><span class="mi">1</span><span class="p">)]</span>
        <span class="n">exp</span>  <span class="o">=</span> <span class="n">exp</span><span class="p">[:,</span> <span class="n">exp</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">argsort</span><span class="p">()]</span>
        <span class="n">exp</span>  <span class="o">=</span> <span class="n">exp</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">Polynomial</span><span class="p">(</span><span class="n">exp</span><span class="p">)</span></div>

            
<div class="viewcode-block" id="Polynomial.pri_exp">
<a class="viewcode-back" href="../../../api_reference/element.html#tensormesh.element.polynomial.Polynomial.pri_exp">[docs]</a>
    <span class="nd">@classmethod</span> 
    <span class="k">def</span> <span class="nf">pri_exp</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> 
                <span class="n">order</span><span class="p">:</span><span class="nb">int</span><span class="p">,</span>
                <span class="n">dtype</span><span class="p">:</span><span class="n">torch</span><span class="o">.</span><span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span>
                <span class="n">device</span><span class="p">:</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
                <span class="p">)</span><span class="o">-&gt;</span><span class="s1">&#39;Polynomial&#39;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Creates a prismatic polynomial with terms up to maximum total degree.</span>

<span class="sd">        For order n, includes all terms where x+y &lt; n+1, sorted by total degree.</span>

<span class="sd">        For example, with order=1, creates polynomial with terms:</span>
<span class="sd">        :math:`P(x,y,z) = a_0 + a_1x + a_2y + a_3z`</span>

<span class="sd">        With order=2, creates polynomial with terms:</span>
<span class="sd">        :math:`P(x,y,z) = a_0 + a_1x + a_2y + a_3z + a_4x^2 + a_5xy + a_6y^2 + a_7xz + a_8yz + a_9z^2`</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        .. code-block:: python</span>

<span class="sd">            # Create prismatic polynomial of order 2</span>
<span class="sd">            poly = Polynomial.pri_exp(2)</span>
<span class="sd">            print(poly)  # 1 + x + y + z + x^2 + xy + y^2 + xz + yz + z^2</span>
<span class="sd">            </span>
<span class="sd">            # Create with specific dtype and device</span>
<span class="sd">            poly = Polynomial.pri_exp(2, dtype=torch.float64, device=torch.device(&#39;cuda&#39;))</span>
<span class="sd">            print(poly.dtype)  # torch.float64</span>
<span class="sd">            print(poly.device)  # cuda:0</span>
<span class="sd">            </span>
<span class="sd">            # Evaluate polynomial at point x</span>
<span class="sd">            x = torch.tensor([1.0, 2.0, 0.5], device=&#39;cuda&#39;, dtype=torch.float64)  # [x,y,z]</span>
<span class="sd">            print(poly(x))  # Evaluates polynomial at (1,2,0.5)</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        order : int</span>
<span class="sd">            Maximum polynomial order</span>
<span class="sd">        dtype : torch.dtype, optional</span>
<span class="sd">            Data type of polynomial coefficients</span>
<span class="sd">        device : torch.device, optional</span>
<span class="sd">            Device to store polynomial on</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        polynomial : Polynomial</span>
<span class="sd">            Prismatic polynomial with n_vars=3 and appropriate number of terms</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">axes</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">order</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> 
                              <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">order</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> 
                              <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">order</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> 
                              <span class="n">indexing</span><span class="o">=</span><span class="s1">&#39;xy&#39;</span><span class="p">)</span>
        <span class="n">axes</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">axes</span><span class="p">))</span>
        <span class="n">exp</span>  <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">axes</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="n">exp</span>  <span class="o">=</span> <span class="n">exp</span><span class="p">[:,</span> <span class="n">exp</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">+</span><span class="n">exp</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">order</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">exp</span>  <span class="o">=</span> <span class="n">exp</span><span class="p">[:,</span> <span class="n">exp</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">argsort</span><span class="p">()]</span>
        <span class="n">exp</span>  <span class="o">=</span> <span class="n">exp</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">Polynomial</span><span class="p">(</span><span class="n">exp</span><span class="p">)</span></div>
</div>


<div class="viewcode-block" id="Polynomials">
<a class="viewcode-back" href="../../../api_reference/element.html#tensormesh.element.polynomial.Polynomials">[docs]</a>
<span class="k">class</span> <span class="nc">Polynomials</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>

<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A collection of polynomials that can be evaluated and manipulated together.</span>

<span class="sd">    This class represents a batch of polynomials, allowing vectorized operations across multiple polynomials.</span>
<span class="sd">    Each polynomial has the same number of variables and terms, but can have different coefficients.</span>

<span class="sd">    The polynomials are stored in a batched format with coefficients and exponents tensors:</span>

<span class="sd">    - Coefficients tensor shape: [n_poly1, ..., n_terms] </span>
<span class="sd">    - Exponents tensor shape: [n_poly1, ..., n_vars, n_terms]</span>

<span class="sd">    Where n_poly1, ... are the batch dimensions.</span>

<span class="sd">    </span>
<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    .. code-block:: python</span>

<span class="sd">        # Create a batch of 2 quadratic polynomials in 2 variables</span>
<span class="sd">        exp = torch.tensor([[[0,1,0,2,0], [0,0,1,0,2]],</span>
<span class="sd">                          [[0,1,0,2,0], [0,0,1,0,2]]])  # [2, 2, 5]</span>
<span class="sd">        coef = torch.tensor([[1,2,3,4,5], [2,3,4,5,6]]) # [2, 5]</span>
<span class="sd">        polys = Polynomials(exp, coef)</span>

<span class="sd">        # Print batch shape and dimensions</span>
<span class="sd">        print(polys.shape)     # (2,)</span>
<span class="sd">        print(polys.n_vars)    # 2 </span>
<span class="sd">        print(polys.n_terms)   # 5</span>

<span class="sd">        # Evaluate polynomials at points</span>
<span class="sd">        x = torch.tensor([[1.0, 2.0], [3.0, 4.0]])  # [2, 2]</span>
<span class="sd">        y = polys(x)  # Evaluates both polynomials at their respective points</span>

<span class="sd">        # Take derivatives</span>
<span class="sd">        d_polys = polys.deriv(0)  # Derivative with respect to first variable</span>
<span class="sd">        </span>
<span class="sd">        # Convert to individual polynomials</span>
<span class="sd">        poly_list = [polys[i] for i in range(len(polys))]</span>

<span class="sd">        # Create with specific dtype and device</span>
<span class="sd">        exp = exp.cuda().double()</span>
<span class="sd">        coef = coef.cuda().double() </span>
<span class="sd">        polys = Polynomials(exp, coef)</span>
<span class="sd">        print(polys.dtype)    # torch.float64</span>
<span class="sd">        print(polys.device)   # cuda:0</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    exp : torch.Tensor</span>
<span class="sd">        Tensor of exponents with shape [n_poly1, ..., n_vars, n_terms]</span>
<span class="sd">    coef : torch.Tensor, optional</span>
<span class="sd">        Tensor of coefficients with shape [n_poly1, ..., n_terms]. If None, defaults to ones.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    _coef : torch.Tensor</span>
<span class="sd">        The coefficients tensor</span>
<span class="sd">    _exp : torch.Tensor  </span>
<span class="sd">        The exponents tensor</span>
<span class="sd">    n_polys : Tuple[int, ...]</span>
<span class="sd">        The batch dimensions</span>
<span class="sd">    n_vars : int</span>
<span class="sd">        Number of variables in each polynomial</span>
<span class="sd">    n_terms : int</span>
<span class="sd">        Number of terms in each polynomial</span>
<span class="sd">    device : torch.device</span>
<span class="sd">        The device the tensors are stored on</span>
<span class="sd">    dtype : torch.dtype</span>
<span class="sd">        The data type of the tensors</span>
<span class="sd">    shape : Tuple[int, ...]</span>
<span class="sd">        The batch dimensions (same as n_polys)</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">_coef</span><span class="p">:</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> 
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Coefficients tensor of shape [n_poly1, ..., n_terms] where:</span>
<span class="sd">    </span>
<span class="sd">    * n_poly1, ... = batch dimensions for multiple polynomials</span>
<span class="sd">    * n_terms = number of terms in each polynomial</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">_exp</span><span class="p">:</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>  
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Exponents tensor of shape [n_poly1, ..., n_vars, n_terms] where:</span>
<span class="sd">    </span>
<span class="sd">    * n_poly1, ... = batch dimensions for multiple polynomials</span>
<span class="sd">    * n_vars = number of variables in each polynomial</span>
<span class="sd">    * n_terms = number of terms in each polynomial</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">n_polys</span><span class="p">:</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Batch dimensions for multiple polynomials</span>
<span class="sd">    :no-index:</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">n_vars</span><span class="p">:</span><span class="nb">int</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Number of variables in each polynomial</span>
<span class="sd">    :no-index:</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">n_terms</span><span class="p">:</span><span class="nb">int</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Number of terms in each polynomial</span>
<span class="sd">    :no-index:</span>
<span class="sd">    &quot;&quot;&quot;</span>

<div class="viewcode-block" id="Polynomials.__init__">
<a class="viewcode-back" href="../../../api_reference/element.html#tensormesh.element.polynomial.Polynomials.__init__">[docs]</a>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> 
                 <span class="n">exp</span><span class="p">:</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> 
                 <span class="n">coef</span><span class="p">:</span><span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize multiple polynomials with exponents and coefficients.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        exp : torch.Tensor</span>
<span class="sd">            Exponents tensor of shape :math:`[N_1, \ldots, N_v, N_t]` where:</span>
<span class="sd">            * :math:`N_1, \ldots` = batch dimensions for multiple polynomials</span>
<span class="sd">            * :math:`N_v` = number of variables in each polynomial </span>
<span class="sd">            * :math:`N_t` = number of terms in each polynomial</span>
<span class="sd">        coef : Optional[torch.Tensor], optional</span>
<span class="sd">            Coefficients tensor of shape :math:`[N_1, \ldots, N_t]` where:</span>
<span class="sd">            * :math:`N_1, \ldots` = batch dimensions for multiple polynomials</span>
<span class="sd">            * :math:`N_t` = number of terms in each polynomial</span>
<span class="sd">            If None, coefficients will be initialized as ones.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        .. code-block:: python</span>

<span class="sd">            # Create 2x3 grid of polynomials x^2y + 2xy^2 + 3</span>
<span class="sd">            exp = torch.tensor([[[2,1,0], [1,2,0]]]).repeat(2,3,1,1)  # [2,3,2,3]</span>
<span class="sd">            coef = torch.tensor([[1,2,3]]).repeat(2,3,1)              # [2,3,3]</span>
<span class="sd">            polys = Polynomials(exp, coef)  # 2x3 grid of polynomials</span>

<span class="sd">            # Print shape</span>
<span class="sd">            print(polys.shape)  # (2,3)</span>

<span class="sd">            # Access individual polynomials</span>
<span class="sd">            print(polys[0,0])  # x^2y + 2xy^2 + 3</span>
<span class="sd">            print(polys[1,2])  # x^2y + 2xy^2 + 3</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="o">*</span><span class="n">n_polys</span><span class="p">,</span> <span class="n">n_vars</span><span class="p">,</span> <span class="n">n_terms</span> <span class="o">=</span> <span class="n">exp</span><span class="o">.</span><span class="n">shape</span>
        <span class="k">if</span> <span class="n">coef</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">coef</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="o">*</span><span class="n">n_polys</span><span class="p">,</span> <span class="n">n_terms</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">exp</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">exp</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">n_polys</span><span class="p">)):</span>
            <span class="k">assert</span> <span class="n">coef</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="n">n_polys</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        <span class="k">assert</span> <span class="n">coef</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">n_terms</span>
        <span class="k">assert</span> <span class="n">exp</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">coef</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;exp and coef should have the same dtype, but got </span><span class="si">{</span><span class="n">exp</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s2"> and </span><span class="si">{</span><span class="n">coef</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="k">assert</span> <span class="n">exp</span><span class="o">.</span><span class="n">device</span> <span class="o">==</span> <span class="n">coef</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;exp and coef should have the same device, but got </span><span class="si">{</span><span class="n">exp</span><span class="o">.</span><span class="n">device</span><span class="si">}</span><span class="s2"> and </span><span class="si">{</span><span class="n">coef</span><span class="o">.</span><span class="n">device</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="c1"># self._coef  = coef</span>
        <span class="c1"># self._exp   = exp</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;_coef&#39;</span><span class="p">,</span> <span class="n">coef</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;_exp&#39;</span><span class="p">,</span> <span class="n">exp</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_polys</span> <span class="o">=</span> <span class="n">n_polys</span> 
        <span class="bp">self</span><span class="o">.</span><span class="n">n_vars</span>  <span class="o">=</span> <span class="n">n_vars</span> 
        <span class="bp">self</span><span class="o">.</span><span class="n">n_terms</span> <span class="o">=</span> <span class="n">n_terms</span></div>


    
    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_polys</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    
<div class="viewcode-block" id="Polynomials.numel">
<a class="viewcode-back" href="../../../api_reference/element.html#tensormesh.element.polynomial.Polynomials.numel">[docs]</a>
    <span class="k">def</span> <span class="nf">numel</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">math</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_polys</span><span class="p">)</span></div>


    <span class="nd">@property</span> 
    <span class="k">def</span> <span class="nf">shape</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get batch dimensions of polynomials.</span>
<span class="sd">        :no-index:</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_polys</span><span class="p">)</span>
    
    <span class="nd">@property</span> 
    <span class="k">def</span> <span class="nf">ndim</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_polys</span><span class="p">)</span>
    
    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">device</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_coef</span><span class="o">.</span><span class="n">device</span>
    
    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">dtype</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_coef</span><span class="o">.</span><span class="n">dtype</span>

<div class="viewcode-block" id="Polynomials.dim">
<a class="viewcode-back" href="../../../api_reference/element.html#tensormesh.element.polynomial.Polynomials.dim">[docs]</a>
    <span class="k">def</span> <span class="nf">dim</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_polys</span><span class="p">)</span></div>

    
    <span class="k">def</span> <span class="fm">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_iter_index</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="fm">__next__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_iter_index</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
            <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">_iter_index</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_iter_index</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="k">return</span> <span class="n">result</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">StopIteration</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">indices</span><span class="p">)</span><span class="o">-&gt;</span><span class="n">Union</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>
                                    <span class="s1">&#39;Polynomial&#39;</span><span class="p">,</span>
                                    <span class="s1">&#39;Polynomials&#39;</span><span class="p">]:</span>
        <span class="n">_coef</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_coef</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span>
        <span class="n">_exp</span>  <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_exp</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">_coef</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">_coef</span><span class="p">,</span> <span class="n">_exp</span>
        <span class="k">elif</span> <span class="n">_coef</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">Polynomial</span><span class="p">(</span><span class="n">_exp</span><span class="p">,</span> <span class="n">_coef</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">_coef</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">Polynomials</span><span class="p">(</span><span class="n">_exp</span><span class="p">,</span> <span class="n">_coef</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Invalid input shape </span><span class="si">{</span><span class="n">indices</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="fm">__str__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">max_show_item</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>

        <span class="k">def</span> <span class="nf">vector2str</span><span class="p">(</span><span class="n">max_show_item</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
            <span class="n">string</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">)):</span>
                <span class="n">string</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="fm">__str__</span><span class="p">(</span><span class="n">max_show_item</span><span class="p">))</span>

            <span class="k">if</span> <span class="n">max_show_item</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">max_show_item</span><span class="o">*</span><span class="mi">2</span><span class="p">:</span>
                <span class="k">return</span>  <span class="s2">&quot;[&quot;</span> <span class="o">+</span> <span class="s2">&quot;,</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">string</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;]&quot;</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="s2">&quot;[&quot;</span> <span class="o">+</span> <span class="s2">&quot;,</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">string</span><span class="p">[:</span><span class="n">max_show_item</span><span class="p">])</span> <span class="o">+</span> <span class="s2">&quot;,</span><span class="se">\n</span><span class="s2">...</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">+</span> <span class="s2">&quot;,</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">string</span><span class="p">[</span><span class="o">-</span><span class="n">max_show_item</span><span class="p">:])</span> <span class="o">+</span> <span class="s2">&quot;]&quot;</span> 

        <span class="k">def</span> <span class="nf">matrix2str</span><span class="p">(</span><span class="n">max_show_row</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">max_show_col</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
            <span class="n">matrix</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
                <span class="n">row</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
                    <span class="n">row</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">]</span><span class="o">.</span><span class="fm">__str__</span><span class="p">(</span><span class="n">max_show_col</span><span class="p">))</span>
                <span class="n">matrix</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">row</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">max_show_row</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">max_show_row</span><span class="o">*</span><span class="mi">2</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">max_show_col</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">max_show_col</span><span class="o">*</span><span class="mi">2</span><span class="p">:</span>
                    <span class="k">return</span> <span class="s2">&quot;[&quot;</span><span class="o">+</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="s2">&quot;[&quot;</span><span class="o">+</span><span class="s2">&quot;, &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">row</span><span class="p">)</span><span class="o">+</span><span class="s2">&quot;]&quot;</span> <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">matrix</span><span class="p">])</span><span class="o">+</span><span class="s2">&quot;]&quot;</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">return</span> <span class="s2">&quot;[&quot;</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="s2">&quot;[&quot;</span><span class="o">+</span><span class="s2">&quot;, &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">row</span><span class="p">[:</span><span class="n">max_show_col</span><span class="p">])</span><span class="o">+</span><span class="s2">&quot;, ..., &quot;</span><span class="o">+</span><span class="s2">&quot;, &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="o">-</span><span class="n">max_show_col</span><span class="p">:])</span><span class="o">+</span><span class="s2">&quot;]&quot;</span> <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">matrix</span><span class="p">])</span> <span class="o">+</span> <span class="s2">&quot;]&quot;</span>

            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">max_show_col</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">max_show_col</span><span class="o">*</span><span class="mi">2</span><span class="p">:</span>
                    <span class="k">return</span> <span class="s2">&quot;[&quot;</span><span class="o">+</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="s2">&quot;[&quot;</span><span class="o">+</span><span class="s2">&quot;, &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">row</span><span class="p">)</span><span class="o">+</span><span class="s2">&quot;]&quot;</span> <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">matrix</span><span class="p">[:</span><span class="n">max_show_row</span><span class="p">]])</span><span class="o">+</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">...</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">+</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="s2">&quot;[&quot;</span><span class="o">+</span><span class="s2">&quot;, &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">row</span><span class="p">)</span><span class="o">+</span><span class="s2">&quot;]&quot;</span> <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">matrix</span><span class="p">[</span><span class="o">-</span><span class="n">max_show_row</span><span class="p">:]])</span><span class="o">+</span><span class="s2">&quot;]&quot;</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">return</span> <span class="p">(</span><span class="s2">&quot;[&quot;</span> <span class="o">+</span>
                            <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="s2">&quot;[&quot;</span><span class="o">+</span><span class="s2">&quot;, &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">row</span><span class="p">[:</span><span class="n">max_show_col</span><span class="p">])</span><span class="o">+</span><span class="s2">&quot;, ..., &quot;</span><span class="o">+</span><span class="s2">&quot;, &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="o">-</span><span class="n">max_show_col</span><span class="p">:])</span><span class="o">+</span><span class="s2">&quot;]&quot;</span> <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">matrix</span><span class="p">[:</span><span class="n">max_show_row</span><span class="p">]])</span> <span class="o">+</span> 
                            <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">...</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="o">+</span> 
                            <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="s2">&quot;[&quot;</span><span class="o">+</span><span class="s2">&quot;, &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">row</span><span class="p">[:</span><span class="n">max_show_col</span><span class="p">])</span><span class="o">+</span><span class="s2">&quot;, ..., &quot;</span><span class="o">+</span><span class="s2">&quot;, &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="o">-</span><span class="n">max_show_col</span><span class="p">:])</span><span class="o">+</span><span class="s2">&quot;]&quot;</span> <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">matrix</span><span class="p">[</span><span class="o">-</span><span class="n">max_show_row</span><span class="p">:]])</span> <span class="o">+</span> 
                            <span class="s2">&quot;]&quot;</span><span class="p">)</span>
        
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">vector2str</span><span class="p">(</span><span class="n">max_show_item</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">matrix2str</span><span class="p">(</span><span class="n">max_show_item</span><span class="p">,</span> <span class="n">max_show_item</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;PolynomialTensor[</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">] n_terms=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">n_terms</span><span class="si">}</span><span class="s2"> n_vars=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">n_vars</span><span class="si">}</span><span class="s2">&quot;</span>
    
    <span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="fm">__str__</span><span class="p">()</span>

<div class="viewcode-block" id="Polynomials.forward">
<a class="viewcode-back" href="../../../api_reference/element.html#tensormesh.element.polynomial.Polynomials.forward">[docs]</a>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span><span class="o">-&gt;</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Evaluates the polynomial at the given input points.</span>

<span class="sd">        For a polynomial :math:`p(x) = \sum_i c_i \prod_j x_j^{e_{ij}}`, computes:</span>

<span class="sd">        1. Evaluates each term by raising inputs to exponents</span>
<span class="sd">        2. Multiplies terms by coefficients </span>
<span class="sd">        3. Sums the terms</span>

<span class="sd">        For example, for polynomial :math:`2x^2y + 3xy^2` with point :math:`[2,3]`:</span>

<span class="sd">        .. math::</span>
<span class="sd">            2(2^2 \cdot 3^1) + 3(2^1 \cdot 3^2) = 2(12) + 3(18) = 78</span>

<span class="sd">        The computation is vectorized across batches and/or multiple polynomials.</span>
<span class="sd">        </span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        .. code-block:: python</span>

<span class="sd">            # Single polynomial evaluation</span>
<span class="sd">            exp = torch.tensor([[2, 1], [1, 2]])  # x^2y + xy^2</span>
<span class="sd">            coef = torch.tensor([2, 3])           # 2x^2y + 3xy^2</span>
<span class="sd">            poly = Polynomial(exp, coef)</span>
<span class="sd">            x = torch.tensor([2.0, 3.0])          # Point [2,3]</span>
<span class="sd">            print(poly(x))                        # 2*(2^2*3) + 3*(2*3^2) = 78.0</span>

<span class="sd">            # Batch evaluation</span>
<span class="sd">            x_batch = torch.tensor([[2.0, 3.0], [1.0, 2.0]])  # 2 points</span>
<span class="sd">            print(poly(x_batch))                  # [78.0, 14.0]</span>

<span class="sd">            # Multiple polynomials</span>
<span class="sd">            polys = Polynomials([poly, poly])     # 2 copies of same polynomial</span>
<span class="sd">            print(polys(x))                       # [78.0, 78.0]</span>

<span class="sd">            # Batch + multiple polynomials </span>
<span class="sd">            print(polys(x_batch))                 # [[78.0, 78.0], [14.0, 14.0]]</span>

<span class="sd">       </span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        x: torch.Tensor [n_batch, n_poly1, ..., n_vars] or [n_poly1, ..., n_vars]</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        torch.Tensor [n_batch, n_poly1, ...] or [n_poly1, ...]</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_exp_terms</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>             <span class="c1"># [n_batch, n_poly1, ..., n_terms] or [n_poly1, ..., n_terms]</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">apply_coefficient</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>         <span class="c1"># [n_batch, n_poly1, ...] or [n_poly1, ...]</span>
        <span class="k">return</span> <span class="n">x</span></div>

    
<div class="viewcode-block" id="Polynomials.get_exp_terms">
<a class="viewcode-back" href="../../../api_reference/element.html#tensormesh.element.polynomial.Polynomials.get_exp_terms">[docs]</a>
    <span class="k">def</span> <span class="nf">get_exp_terms</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span><span class="o">-&gt;</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Evaluates the polynomial terms for each input point by raising to the appropriate exponents.</span>

<span class="sd">        For each input point :math:`x` and term with exponents :math:`e`, computes:</span>

<span class="sd">        .. math::</span>
<span class="sd">            x_0^{e_0} \cdot x_1^{e_1} \cdot \ldots \cdot x_n^{e_n}</span>

<span class="sd">        For example, for polynomial :math:`x^2y` with point :math:`[2,3]`, computes:</span>

<span class="sd">        .. math::</span>
<span class="sd">            2^2 \cdot 3^1 = 12</span>

<span class="sd">        The computation is vectorized across batches and/or multiple polynomials.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        .. code-block:: python</span>

<span class="sd">            # Single polynomial evaluation</span>
<span class="sd">            exp = torch.tensor([[2, 1], [1, 2]])  # x^2y + xy^2</span>
<span class="sd">            coef = torch.tensor([2, 3])           # 2x^2y + 3xy^2</span>
<span class="sd">            poly = Polynomial(exp, coef)</span>
<span class="sd">            x = torch.tensor([2.0, 3.0])          # Point [2,3]</span>
<span class="sd">            terms = poly.get_exp_terms(x)         # [12, 18] (2^2*3, 2*3^2)</span>

<span class="sd">            # Batch evaluation</span>
<span class="sd">            x_batch = torch.tensor([[2.0, 3.0], [1.0, 2.0]])  # 2 points</span>
<span class="sd">            terms = poly.get_exp_terms(x_batch)   # [[12, 18], [2, 4]]</span>

<span class="sd">            # Multiple polynomials</span>
<span class="sd">            polys = Polynomials([poly, poly])     # 2 copies of same polynomial</span>
<span class="sd">            terms = polys.get_exp_terms(x)        # [[12, 18], [12, 18]]</span>

<span class="sd">            # Batch + multiple polynomials</span>
<span class="sd">            terms = polys.get_exp_terms(x_batch)  # [[[12, 18], [12, 18]], </span>
<span class="sd">                                                 #  [[2, 4], [2, 4]]]</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        x: torch.Tensor [n_batch, n_poly1, ..., n_vars] or [n_poly1, ..., n_vars]</span>
<span class="sd">            Input points to evaluate. Can include a batch dimension.</span>
<span class="sd">            n_poly1, ... are optional polynomial batch dimensions.</span>
<span class="sd">            Last dimension must match number of variables.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        torch.Tensor [n_batch, n_poly1, ..., n_terms] or [n_poly1, ..., n_terms]</span>
<span class="sd">            Evaluated terms for each input point.</span>
<span class="sd">            Output has same batch/polynomial dimensions as input.</span>
<span class="sd">            Last dimension contains values for each term.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="n">x</span><span class="o">.</span><span class="n">device</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;x and self should have the same device, but got </span><span class="si">{</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="si">}</span><span class="s2"> and </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="k">assert</span> <span class="n">x</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;x and self should have the same dtype, but got </span><span class="si">{</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s2"> and </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">+</span> <span class="mi">2</span><span class="p">:</span>
            <span class="c1"># shape check</span>
            <span class="n">n_batch</span><span class="p">,</span> <span class="o">*</span><span class="n">n_polys</span><span class="p">,</span> <span class="n">n_vars</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span>
            <span class="k">assert</span> <span class="n">n_polys</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_polys</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;Expected n_polys: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">n_polys</span><span class="si">}</span><span class="s2"> but got </span><span class="si">{</span><span class="n">n_polys</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="k">assert</span> <span class="n">n_vars</span>  <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_vars</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;Expected n_vars: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">n_vars</span><span class="si">}</span><span class="s2"> but got </span><span class="si">{</span><span class="n">n_vars</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="n">x</span>    <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">_exp</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="o">...</span><span class="p">])</span>  <span class="c1"># [n_batch, n_poly1, ..., n_vars, n_terms]</span>
            <span class="n">x</span>    <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">2</span><span class="p">)</span> <span class="c1"># [n_batch, n_poly1, ..., n_terms]</span>
        <span class="k">elif</span> <span class="n">x</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span><span class="p">:</span>
            <span class="c1"># shape check </span>
            <span class="o">*</span><span class="n">n_polys</span><span class="p">,</span> <span class="n">n_vars</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span> 
            <span class="k">assert</span> <span class="n">n_polys</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_polys</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;Expected n_polys: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">n_polys</span><span class="si">}</span><span class="s2"> but got </span><span class="si">{</span><span class="n">n_polys</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="k">assert</span> <span class="n">n_vars</span>  <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_vars</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;Expected n_vars: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">n_vars</span><span class="si">}</span><span class="s2"> but got </span><span class="si">{</span><span class="n">n_vars</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="n">x</span>    <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">_exp</span><span class="p">)</span>  <span class="c1"># [n_poly1, ..., n_vars, n_terms]</span>
            <span class="n">x</span>    <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">2</span><span class="p">)</span> <span class="c1"># [n_poly1, ..., n_terms]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Should be shape of [n_batch, </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">n_vars</span><span class="si">}</span><span class="s2">] or [</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">n_vars</span><span class="si">}</span><span class="s2">], but got Invalid input shape </span><span class="si">{</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span></div>

    
<div class="viewcode-block" id="Polynomials.apply_coefficient">
<a class="viewcode-back" href="../../../api_reference/element.html#tensormesh.element.polynomial.Polynomials.apply_coefficient">[docs]</a>
    <span class="k">def</span> <span class="nf">apply_coefficient</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>  <span class="n">x</span><span class="p">:</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span><span class="o">-&gt;</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Applies the polynomial coefficients to the evaluated terms.</span>

<span class="sd">        For each polynomial with coefficients :math:`c` and evaluated terms :math:`t`, computes:</span>

<span class="sd">        .. math::</span>
<span class="sd">            \sum_i c_i t_i</span>

<span class="sd">        For example, for polynomial :math:`2x^2 + 3y` with evaluated terms :math:`[4,3]`, computes:</span>

<span class="sd">        .. math::</span>
<span class="sd">            2 \cdot 4 + 3 \cdot 3 = 17</span>

<span class="sd">        The computation is vectorized across batches and/or multiple polynomials.</span>

<span class="sd">        The coefficients are broadcast to match the batch dimensions of the input.</span>


<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        .. code-block:: python</span>

<span class="sd">            # Single polynomial evaluation</span>
<span class="sd">            exp = torch.tensor([[2, 1], [0, 1]])  # x^2, y</span>
<span class="sd">            coef = torch.tensor([2, 3])           # 2x^2 + 3y</span>
<span class="sd">            poly = Polynomial(exp, coef)</span>
<span class="sd">            terms = torch.tensor([4, 3])          # terms = [x^2=4, y=3]</span>
<span class="sd">            poly.apply_coefficient(terms)          # 2*4 + 3*3 = 17</span>

<span class="sd">            # Batch evaluation</span>
<span class="sd">            terms = torch.tensor([[4, 3], [1, 2]]) # 2 points</span>
<span class="sd">            poly.apply_coefficient(terms)          # [2*4 + 3*3, 2*1 + 3*2]</span>

<span class="sd">            # Multiple polynomials</span>
<span class="sd">            exp = torch.tensor([[[2, 1], [0, 1]], # 2x^2 + 3y</span>
<span class="sd">                              [[1, 2], [1, 0]]])  # x^2y + xy</span>
<span class="sd">            coef = torch.tensor([[2, 3], [1, 1]])</span>
<span class="sd">            poly = Polynomials(exp, coef)</span>
<span class="sd">            terms = torch.tensor([[4, 3], [12, 2]]) # terms for each polynomial</span>
<span class="sd">            poly.apply_coefficient(terms)          # [2*4 + 3*3, 1*12 + 1*2]</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        x:torch.Tensor</span>
<span class="sd">            ND Tensor of shape [n_batch, n_poly1, ..., n_terms] or [n_poly1, ..., n_terms]</span>
<span class="sd">            </span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        torch.Tensor</span>
<span class="sd">            ND Tensor of shape [n_batch, n_poly1, ..., n_poly2] or [n_poly1, ..., n_poly2] where:</span>
<span class="sd">            </span>
<span class="sd">            * n_batch = number of input points (optional)</span>
<span class="sd">            * n_poly1, ..., n_poly2 = polynomial dimensions</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="n">x</span><span class="o">.</span><span class="n">device</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;x and self should have the same device, but got </span><span class="si">{</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="si">}</span><span class="s2"> and </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="k">assert</span> <span class="n">x</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;x and self should have the same dtype, but got </span><span class="si">{</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s2"> and </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="k">assert</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_terms</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">()):</span>
            <span class="k">assert</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span> <span class="o">-</span> <span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_polys</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="o">-</span><span class="n">i</span><span class="p">],</span> <span class="sa">f</span><span class="s2">&quot;Expected </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">n_polys</span><span class="si">}</span><span class="s2"> but got </span><span class="si">{</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span><span class="o">-</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span>


        <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">+</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">n_batch</span><span class="p">,</span> <span class="o">*</span><span class="n">n_polys</span><span class="p">,</span> <span class="n">n_terms</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span>
            <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_coef</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">*</span><span class="n">n_polys</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_terms</span><span class="p">)</span> <span class="o">*</span> <span class="n">x</span> <span class="c1"># [n_batch, n_poly1, ..., n_terms]</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>           <span class="c1"># [n_batch, n_poly1, ..., n_poly2]</span>
        <span class="k">elif</span> <span class="n">x</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span><span class="o">+</span><span class="mi">1</span><span class="p">:</span>
            <span class="o">*</span><span class="n">n_polys</span><span class="p">,</span> <span class="n">n_terms</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span>
            <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_coef</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_terms</span><span class="p">)</span> <span class="o">*</span> <span class="n">x</span> <span class="c1"># [n_poly1, ..., n_terms]</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span> <span class="c1"># [n_poly1, ..., n_poly2]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Expected input of shape [n_batch, </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">n_vars</span><span class="si">}</span><span class="s2">] or [</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">n_vars</span><span class="si">}</span><span class="s2">], but got </span><span class="si">{</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span></div>

    
<div class="viewcode-block" id="Polynomials.map">
<a class="viewcode-back" href="../../../api_reference/element.html#tensormesh.element.polynomial.Polynomials.map">[docs]</a>
    <span class="k">def</span> <span class="nf">map</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span><span class="o">-&gt;</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Evaluates the polynomial at given input points.</span>

<span class="sd">        For each polynomial with coefficients c and exponents e, computes:</span>

<span class="sd">        .. math::</span>
<span class="sd">            \sum_i c_i \prod_j x_j^{e_{ij}}</span>

<span class="sd">        For example, for polynomial :math:`2x^2 + 3y` evaluated at point :math:`(2,3)`, computes:</span>

<span class="sd">        .. math::</span>
<span class="sd">            2 \cdot 2^2 + 3 \cdot 3 = 17</span>

<span class="sd">        The computation is vectorized across batches and/or multiple polynomials.</span>
<span class="sd">        The input points are broadcast to match the polynomial dimensions.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        .. code-block:: python</span>

<span class="sd">            # Single polynomial evaluation</span>
<span class="sd">            exp = torch.tensor([[2, 1], [1, 2]])  # x^2y, xy^2</span>
<span class="sd">            coef = torch.tensor([2, 3])           # 2x^2y + 3xy^2</span>
<span class="sd">            poly = Polynomial(exp, coef)</span>
<span class="sd">            x = torch.tensor([2.0, 3.0])          # Point (2,3)</span>
<span class="sd">            poly.map(x)                           # 2*(2^2*3) + 3*(2*3^2) = 24 + 54 = 78</span>
<span class="sd">            # tensor(78.)</span>

<span class="sd">            # Batch evaluation</span>
<span class="sd">            x = torch.tensor([[2.0, 3.0], [1.0, 2.0]])  # Two points</span>
<span class="sd">            poly.map(x)                                  # Evaluate at both points</span>
<span class="sd">            # tensor([78., 14.])</span>

<span class="sd">            # Multiple polynomials</span>
<span class="sd">            polys = Polynomials([poly, poly])  # Two copies of same polynomial</span>
<span class="sd">            x = torch.tensor([2.0, 3.0])       # Single point</span>
<span class="sd">            polys.map(x)                       # Evaluate both polynomials</span>
<span class="sd">            # tensor([78., 78.])</span>

<span class="sd">            # Batch + multiple polynomials</span>
<span class="sd">            x = torch.tensor([[2.0, 3.0], [1.0, 2.0]])  # Two points</span>
<span class="sd">            polys.map(x)                                 # Evaluate both polys at both points</span>
<span class="sd">            # tensor([[78., 78.],</span>
<span class="sd">            #         [14., 14.]])</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        x : torch.Tensor</span>
<span class="sd">            Input points tensor of shape [n_batch, n_vars] or [n_vars].</span>
<span class="sd">            Each row represents a point to evaluate the polynomial(s) at.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        torch.Tensor</span>
<span class="sd">            Evaluated polynomial values. Shape is:</span>
<span class="sd">            - [n_batch, n_poly1, ...] if input is [n_batch, n_vars]  </span>
<span class="sd">            - [n_poly1, ...] if input is [n_vars]</span>
<span class="sd">            Where n_poly1, ... are the polynomial batch dimensions.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">map_exp_terms</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="c1"># [n_batch, n_poly1, ..., n_terms] or [n_poly1, ..., n_terms]</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">apply_coefficient</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="c1"># [n_batch, n_poly1, ...,] or [n_poly1, ...,]</span>
        <span class="k">return</span> <span class="n">x</span></div>


<div class="viewcode-block" id="Polynomials.map_exp_terms">
<a class="viewcode-back" href="../../../api_reference/element.html#tensormesh.element.polynomial.Polynomials.map_exp_terms">[docs]</a>
    <span class="k">def</span> <span class="nf">map_exp_terms</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span><span class="o">-&gt;</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Evaluates the polynomial terms at given input points by applying exponents.</span>

<span class="sd">        For each polynomial with exponents e, computes:</span>

<span class="sd">        .. math::</span>
<span class="sd">            \prod_j x_j^{e_{ij}}</span>

<span class="sd">        For example, for polynomial terms :math:`x^2y, xy^2` evaluated at point :math:`(2,3)`, computes:</span>
<span class="sd">        </span>
<span class="sd">        .. math::</span>
<span class="sd">            [2^2 \cdot 3^1, 2^1 \cdot 3^2] = [12, 18]</span>

<span class="sd">        The computation is vectorized across batches and/or multiple polynomials.</span>
<span class="sd">        The input points are broadcast to match the polynomial dimensions.</span>


<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        .. code-block:: python</span>

<span class="sd">            # Single polynomial, single point</span>
<span class="sd">            exp = torch.tensor([[2, 1], [1, 2]])  # x^2y, xy^2</span>
<span class="sd">            poly = Polynomial(exp)</span>
<span class="sd">            x = torch.tensor([2.0, 3.0])  # Point (2,3)</span>
<span class="sd">            terms = poly.map_exp_terms(x)  # Evaluate terms</span>
<span class="sd">            # tensor([12., 18.])  # 2^2 * 3^1, 2^1 * 3^2</span>

<span class="sd">            # Single polynomial, batch of points</span>
<span class="sd">            x = torch.tensor([[2.0, 3.0], [1.0, 2.0]])  # Two points</span>
<span class="sd">            terms = poly.map_exp_terms(x)  # Evaluate terms at each point</span>
<span class="sd">            # tensor([[12., 18.],  # Point 1: 2^2 * 3^1, 2^1 * 3^2</span>
<span class="sd">            #         [1., 4.]])   # Point 2: 1^2 * 2^1, 1^1 * 2^2</span>

<span class="sd">            # Multiple polynomials</span>
<span class="sd">            polys = Polynomials([poly, poly])  # Two copies</span>
<span class="sd">            x = torch.tensor([2.0, 3.0])       # Single point</span>
<span class="sd">            terms = polys.map_exp_terms(x)      # Evaluate terms for both polys</span>
<span class="sd">            # tensor([[12., 18.],</span>
<span class="sd">            #         [12., 18.]])</span>

<span class="sd">            # Batch + multiple polynomials</span>
<span class="sd">            x = torch.tensor([[2.0, 3.0], [1.0, 2.0]])  # Two points</span>
<span class="sd">            terms = polys.map_exp_terms(x)               # Evaluate at each point</span>
<span class="sd">            # tensor([[[12., 18.],</span>
<span class="sd">            #          [12., 18.]],</span>
<span class="sd">            #         [[1., 4.],</span>
<span class="sd">            #          [1., 4.]]])</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        x : torch.Tensor</span>
<span class="sd">            Input points tensor of shape [n_batch, n_vars] or [n_vars].</span>
<span class="sd">            Each row represents a point to evaluate the polynomial terms at.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        torch.Tensor</span>
<span class="sd">            Evaluated polynomial term values. Shape is:</span>
<span class="sd">            - [n_batch, n_poly1, ..., n_terms] if input is [n_batch, n_vars]</span>
<span class="sd">            - [n_poly1, ..., n_terms] if input is [n_vars]</span>
<span class="sd">            Where n_poly1, ... are the polynomial batch dimensions.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="n">x</span><span class="o">.</span><span class="n">device</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;x and self should have the same device, but got </span><span class="si">{</span><span class="n">x</span><span class="o">.</span><span class="n">device</span><span class="si">}</span><span class="s2"> and </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="k">assert</span> <span class="n">x</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;x and self should have the same dtype, but got </span><span class="si">{</span><span class="n">x</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s2"> and </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="k">assert</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_vars</span>
        <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">math</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_polys</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_vars</span><span class="p">)</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">n_polys</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_vars</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">x</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">n_batch</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">math</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_polys</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">n_batch</span><span class="p">,</span> <span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">n_polys</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_vars</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Should be shape of [n_batch, </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">n_vars</span><span class="si">}</span><span class="s2">] or [</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">n_vars</span><span class="si">}</span><span class="s2">], but got Invalid input shape </span><span class="si">{</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
           
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_exp_terms</span><span class="p">(</span><span class="n">x</span><span class="p">)</span></div>


<div class="viewcode-block" id="Polynomials.reshape">
<a class="viewcode-back" href="../../../api_reference/element.html#tensormesh.element.polynomial.Polynomials.reshape">[docs]</a>
    <span class="k">def</span> <span class="nf">reshape</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">:</span><span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">])</span><span class="o">-&gt;</span><span class="s1">&#39;Polynomials&#39;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Reshapes the polynomial batch dimensions.</span>

<span class="sd">        Creates a new Polynomials object with the coefficients and exponents reshaped to the specified dimensions.</span>
<span class="sd">        The total number of elements must remain the same.</span>

<span class="sd">        Similar to torch.reshape(), this operation changes the batch dimensions while preserving the polynomial structure.</span>
<span class="sd">        The n_vars and n_terms dimensions are preserved at the end.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        *args : Sequence[int]</span>
<span class="sd">            The new shape dimensions. The product of these dimensions must equal the product of the original batch dimensions.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Polynomials</span>
<span class="sd">            A new Polynomials object with reshaped batch dimensions.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; poly = Polynomials(exp, coef)  # shape (6,)</span>
<span class="sd">        &gt;&gt;&gt; reshaped = poly.reshape(2,3)   # shape (2,3)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">exps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_exp</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_vars</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_terms</span><span class="p">)</span>
        <span class="n">coef</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_coef</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_terms</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">Polynomials</span><span class="p">(</span><span class="n">exps</span><span class="p">,</span> <span class="n">coef</span><span class="p">)</span></div>

    
<div class="viewcode-block" id="Polynomials.transpose">
<a class="viewcode-back" href="../../../api_reference/element.html#tensormesh.element.polynomial.Polynomials.transpose">[docs]</a>
    <span class="k">def</span> <span class="nf">transpose</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">:</span><span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">])</span><span class="o">-&gt;</span><span class="s1">&#39;Polynomials&#39;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Transposes the polynomial batch dimensions.</span>

<span class="sd">        Creates a new Polynomials object with the coefficients and exponents transposed according to the specified dimension ordering.</span>
<span class="sd">        The n_vars and n_terms dimensions are preserved at the end.</span>

<span class="sd">        Similar to torch.transpose(), this operation permutes the batch dimensions while preserving the polynomial structure.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        *args : Sequence[int]</span>
<span class="sd">            The new ordering of dimensions. Must include all dimensions up to dim().</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Polynomials</span>
<span class="sd">            A new Polynomials object with transposed batch dimensions.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; poly = Polynomials(exp, coef)  # shape (2,3)</span>
<span class="sd">        &gt;&gt;&gt; transposed = poly.transpose(1,0)  # shape (3,2)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">args</span><span class="p">)</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> 
        <span class="n">exps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_exp</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">coef</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_coef</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">())</span>
        <span class="k">return</span> <span class="n">Polynomials</span><span class="p">(</span><span class="n">exps</span><span class="p">,</span> <span class="n">coef</span><span class="p">)</span></div>

        
<div class="viewcode-block" id="Polynomials.deriv">
<a class="viewcode-back" href="../../../api_reference/element.html#tensormesh.element.polynomial.Polynomials.deriv">[docs]</a>
    <span class="k">def</span> <span class="nf">deriv</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">var_ind</span><span class="p">:</span><span class="nb">int</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">-&gt;</span><span class="s1">&#39;Polynomials&#39;</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the derivative of the polynomial with respect to a variable.</span>

<span class="sd">        For a polynomial :math:`p(x_1,\ldots,x_n)`, computes :math:`\frac{\partial p}{\partial x_i}` </span>
<span class="sd">        where i is the specified variable index.</span>

<span class="sd">        For example, given :math:`p(x,y) = ax^ny^m`, the derivatives are:</span>

<span class="sd">        * :math:`\frac{\partial p}{\partial x} = nax^{n-1}y^m`</span>
<span class="sd">        * :math:`\frac{\partial p}{\partial y} = max^ny^{m-1}`</span>

<span class="sd">        The derivative is computed by:</span>

<span class="sd">        1. Decrementing the exponent of the specified variable by 1</span>
<span class="sd">        2. Multiplying coefficients by the original exponent</span>
<span class="sd">        3. Setting terms with exponent 0 to 0</span>


<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        .. code-block:: python</span>

<span class="sd">            # Single polynomial derivative</span>
<span class="sd">            exp = torch.tensor([[2, 1], [1, 2]])  # x^2y + xy^2</span>
<span class="sd">            coef = torch.tensor([2, 3])           # 2x^2y + 3xy^2</span>
<span class="sd">            poly = Polynomial(exp, coef)</span>
<span class="sd">            </span>
<span class="sd">            # Derivative with respect to x</span>
<span class="sd">            dx = poly.deriv(0)                    # 4xy + 3y^2</span>
<span class="sd">            </span>
<span class="sd">            # Derivative with respect to y  </span>
<span class="sd">            dy = poly.deriv(1)                    # 2x^2 + 6xy</span>

<span class="sd">            # Multiple polynomials</span>
<span class="sd">            polys = Polynomials([poly, poly])     # [2x^2y + 3xy^2, 2x^2y + 3xy^2]</span>
<span class="sd">            dx = polys.deriv(0)                   # [4xy + 3y^2, 4xy + 3y^2]</span>
<span class="sd">            dy = polys.deriv(1)                   # [2x^2 + 6xy, 2x^2 + 6xy]</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">            var_ind: int </span>
<span class="sd">                    the index of the variable to be differentiated</span>
<span class="sd">        </span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">            deriv_poly: Polynomial</span>
<span class="sd">                        the derivative of the polynomial</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="n">var_ind</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_vars</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;var_ind should be less than </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">n_vars</span><span class="si">}</span><span class="s2">, but got </span><span class="si">{</span><span class="n">var_ind</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="n">coef</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_coef</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span> <span class="c1"># [n_poly1, ..., n_terms]</span>
        <span class="n">exp</span>  <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_exp</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>  <span class="c1"># [n_poly1, ..., n_vars, n_terms]</span>
        <span class="n">where_constant</span> <span class="o">=</span> <span class="n">exp</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">var_ind</span><span class="p">,</span> <span class="p">:]</span> <span class="o">==</span> <span class="mi">0</span> <span class="c1"># [n_poly1, ..., n_terms]</span>
        <span class="n">exp</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">var_ind</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">exp</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">var_ind</span><span class="p">,</span> <span class="p">:]</span> <span class="o">-</span> <span class="mi">1</span> <span class="c1"># [n_poly1, ..., n_vars, n_terms]</span>
        <span class="n">exp</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">var_ind</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp_min</span><span class="p">(</span><span class="n">exp</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">var_ind</span><span class="p">,</span> <span class="p">:],</span> <span class="mf">0.0</span><span class="p">)</span> <span class="c1"># [n_poly1, ..., n_vars, n_terms]</span>
        <span class="n">mask</span>     <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">coef</span><span class="p">)</span> <span class="c1"># [n_poly1, ..., n_terms]</span>
        <span class="n">mask</span><span class="p">[</span><span class="n">where_constant</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>         <span class="c1"># [n_poly1, ..., n_terms]</span>
        <span class="n">coef</span>     <span class="o">=</span> <span class="n">coef</span> <span class="o">*</span> <span class="p">(</span><span class="n">exp</span><span class="p">[</span><span class="o">...</span><span class="p">,</span> <span class="n">var_ind</span><span class="p">,</span> <span class="p">:]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">mask</span> <span class="c1"># [n_poly1, ..., n_terms]</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="p">(</span><span class="n">exp</span><span class="p">,</span> <span class="n">coef</span><span class="p">)</span></div>

    
<div class="viewcode-block" id="Polynomials.grad">
<a class="viewcode-back" href="../../../api_reference/element.html#tensormesh.element.polynomial.Polynomials.grad">[docs]</a>
    <span class="k">def</span> <span class="nf">grad</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="o">-&gt;</span><span class="s1">&#39;Polynomials&#39;</span><span class="p">:</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the gradient of the polynomial.</span>

<span class="sd">        For a polynomial :math:`p(x_1,\ldots,x_n)`, returns a vector of partial derivatives:</span>
<span class="sd">        :math:`\nabla p = [\frac{\partial p}{\partial x_1}, \ldots, \frac{\partial p}{\partial x_n}]`</span>

<span class="sd">        For example, given :math:`p(x,y) = ax^ny^m`, the gradient is:</span>
<span class="sd">        :math:`\nabla p = [nax^{n-1}y^m, max^ny^{m-1}]`</span>

<span class="sd">        The gradient is computed by taking the derivative with respect to each variable:</span>

<span class="sd">        1. For each variable i=1...n:</span>
<span class="sd">           - Compute :math:`\frac{\partial p}{\partial x_i}` using deriv(i)</span>
<span class="sd">        2. Stack the derivatives into a vector</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        .. code-block:: python</span>

<span class="sd">            # Single polynomial gradient</span>
<span class="sd">            exp = torch.tensor([[2, 1], [1, 2]])  # x^2y + xy^2</span>
<span class="sd">            coef = torch.tensor([2, 3])           # 2x^2y + 3xy^2</span>
<span class="sd">            poly = Polynomial(exp, coef)</span>
<span class="sd">            grad = poly.grad()                    # [4xy + 3y^2, 2x^2 + 6xy]</span>

<span class="sd">            # Multiple polynomials</span>
<span class="sd">            polys = Polynomials([poly, poly])     # [2x^2y + 3xy^2, 2x^2y + 3xy^2]</span>
<span class="sd">            grad = polys.grad()                   # [[4xy + 3y^2, 4xy + 3y^2],</span>
<span class="sd">                                                 #  [2x^2 + 6xy, 2x^2 + 6xy]]</span>

<span class="sd">            # Evaluate gradient at points</span>
<span class="sd">            x = torch.tensor([2.0, 3.0])          # Point [2,3]</span>
<span class="sd">            grad_vals = grad(x)                   # [[36, 36], [24, 24]]</span>

<span class="sd">            # Batch evaluation</span>
<span class="sd">            x_batch = torch.tensor([[2.0, 3.0],   # 2 points</span>
<span class="sd">                                  [1.0, 2.0]])</span>
<span class="sd">            grad_vals = grad(x_batch)             # [[[36, 36], [24, 24]],</span>
<span class="sd">                                                 #  [[8, 8], [4, 4]]]</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        None</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        grad_poly: PolynomialTensor [n_vars, n_poly1, ..., n_polyn] n_vars=n_vars n_terms = n_terms</span>
<span class="sd">                    the gradient of the polynomial</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># TODO: could be more efficient</span>
        <span class="k">return</span> <span class="n">Polynomials</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">deriv</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_vars</span><span class="p">)])</span></div>


<div class="viewcode-block" id="Polynomials.reset_coef">
<a class="viewcode-back" href="../../../api_reference/element.html#tensormesh.element.polynomial.Polynomials.reset_coef">[docs]</a>
    <span class="k">def</span> <span class="nf">reset_coef</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">coef</span><span class="p">:</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Reset the coefficients of the polynomial</span>
<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        coef: torch.Tensor [n_poly, n_terms]</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="n">coef</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">_coef</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;reset coef error: expected </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_coef</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2"> but got </span><span class="si">{</span><span class="n">coef</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="k">assert</span> <span class="n">coef</span><span class="o">.</span><span class="n">device</span><span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;reset coef error: expected </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="si">}</span><span class="s2"> but got </span><span class="si">{</span><span class="n">coef</span><span class="o">.</span><span class="n">device</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="k">assert</span> <span class="n">coef</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;reset coef error: expected </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s2"> but got </span><span class="si">{</span><span class="n">coef</span><span class="o">.</span><span class="n">dtype</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_coef</span> <span class="o">=</span> <span class="n">coef</span>
        <span class="k">return</span> <span class="bp">self</span></div>


<div class="viewcode-block" id="Polynomials.repeat">
<a class="viewcode-back" href="../../../api_reference/element.html#tensormesh.element.polynomial.Polynomials.repeat">[docs]</a>
    <span class="k">def</span> <span class="nf">repeat</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Repeat the polynomial along specified dimensions.</span>

<span class="sd">        Creates a new Polynomials object by repeating the current polynomial&#39;s coefficients and </span>
<span class="sd">        exponents according to the provided repeat dimensions. This is similar to torch.repeat().</span>

<span class="sd">        For example:</span>
<span class="sd">        - repeat(3) creates 3 copies along a new first dimension</span>
<span class="sd">        - repeat(2,3) creates a 2x3 grid of copies in new dimensions</span>

<span class="sd">        The coefficients and exponents are repeated while preserving the polynomial structure,</span>
<span class="sd">        effectively creating multiple independent copies of the same polynomial.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        *args : int</span>
<span class="sd">            The number of repetitions for each dimension. Must match the number of dimensions</span>
<span class="sd">            in the polynomial (self.dim()).</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Polynomials</span>
<span class="sd">            A new Polynomials object with the repeated structure. The shape will be </span>
<span class="sd">            [args[0]*original_shape[0], args[1]*original_shape[1], ...].</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">args</span><span class="p">)</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span>
        <span class="n">exps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_exp</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">coef</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_coef</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">Polynomials</span><span class="p">(</span><span class="n">exps</span><span class="p">,</span> <span class="n">coef</span><span class="p">)</span></div>


<div class="viewcode-block" id="Polynomials.stack">
<a class="viewcode-back" href="../../../api_reference/element.html#tensormesh.element.polynomial.Polynomials.stack">[docs]</a>
    <span class="nd">@classmethod</span> 
    <span class="k">def</span> <span class="nf">stack</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">polys</span><span class="p">:</span><span class="n">Sequence</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">Polynomial</span><span class="p">,</span><span class="s1">&#39;Polynomials&#39;</span><span class="p">]])</span><span class="o">-&gt;</span><span class="s1">&#39;Polynomials&#39;</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Stack multiple polynomials into a single Polynomials object.</span>

<span class="sd">        Takes a sequence of Polynomial or Polynomials objects and stacks them along a new first dimension.</span>
<span class="sd">        All polynomials must have the same number of variables and terms.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        .. code-block:: python</span>

<span class="sd">            # Create two simple polynomials: x^2 + y and 2x + y^2</span>
<span class="sd">            exp1 = torch.tensor([[2,1], [0,1]])  # Exponents for x^2 + y</span>
<span class="sd">            coef1 = torch.tensor([1.0, 1.0])     # Coefficients [1,1]</span>
<span class="sd">            p1 = Polynomial(exp1, coef1)</span>
<span class="sd">            </span>
<span class="sd">            exp2 = torch.tensor([[1,0], [0,2]])  # Exponents for 2x + y^2  </span>
<span class="sd">            coef2 = torch.tensor([2.0, 1.0])     # Coefficients [2,1]</span>
<span class="sd">            p2 = Polynomial(exp2, coef2)</span>
<span class="sd">            </span>
<span class="sd">            # Stack the polynomials</span>
<span class="sd">            stacked = Polynomials.stack([p1, p2])</span>
<span class="sd">            print(stacked.shape)  # (2,)</span>
<span class="sd">            </span>
<span class="sd">            # Evaluate stacked polynomials at point [2,3]</span>
<span class="sd">            x = torch.tensor([2.0, 3.0])</span>
<span class="sd">            print(stacked(x))  # [7, 13] = [(2^2 + 3), (2*2 + 3^2)]</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        polys : Sequence[Union[Polynomial, Polynomials]]</span>
<span class="sd">            Sequence of polynomials to stack. All must have same n_vars, n_terms, dtype and device.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Polynomials</span>
<span class="sd">            A new Polynomials object with shape [len(polys), ...] containing the stacked polynomials.</span>

<span class="sd">        Examples</span>
<span class="sd">        --------</span>
<span class="sd">        &gt;&gt;&gt; p1 = Polynomial(exp1, coef1)  # First polynomial</span>
<span class="sd">        &gt;&gt;&gt; p2 = Polynomial(exp2, coef2)  # Second polynomial with same structure</span>
<span class="sd">        &gt;&gt;&gt; stacked = Polynomials.stack([p1, p2])</span>
<span class="sd">        &gt;&gt;&gt; stacked.shape</span>
<span class="sd">        (2,)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># check shape</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">polys</span><span class="p">)):</span>
            <span class="k">assert</span> <span class="n">polys</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="vm">__class__</span> <span class="o">==</span> <span class="n">polys</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="vm">__class__</span><span class="p">,</span> <span class="s2">&quot;All polynomials must have the same class.&quot;</span>
            <span class="k">assert</span> <span class="p">(</span><span class="n">polys</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">n_vars</span> <span class="o">==</span> <span class="n">polys</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">n_vars</span> <span class="ow">and</span> 
                    <span class="n">polys</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">n_terms</span> <span class="o">==</span> <span class="n">polys</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">n_terms</span><span class="p">),</span> \
                <span class="s2">&quot;All polynomials must have the same number of variables and terms.&quot;</span>
            <span class="k">assert</span> <span class="n">polys</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">polys</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="s2">&quot;All polynomials must have the same dtype.&quot;</span>
            <span class="k">assert</span> <span class="n">polys</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">device</span><span class="o">==</span> <span class="n">polys</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="s2">&quot;All polynomials must have the same device.&quot;</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">polys</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Polynomials</span><span class="p">):</span>
                <span class="k">assert</span> <span class="n">polys</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">n_polys</span> <span class="o">==</span> <span class="n">polys</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">n_polys</span><span class="p">,</span> <span class="s2">&quot;All polynomials must have the same number of polynomials.&quot;</span>
        
        <span class="n">exps</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">p</span><span class="o">.</span><span class="n">_exp</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">polys</span><span class="p">])</span>
        <span class="n">coef</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">p</span><span class="o">.</span><span class="n">_coef</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">polys</span><span class="p">])</span>
        <span class="k">return</span> <span class="bp">cls</span><span class="p">(</span><span class="n">exps</span><span class="p">,</span> <span class="n">coef</span><span class="p">)</span></div>
</div>




   


</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024, walkerchi.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>